{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Naive Bayes, Cross-Validation, and VC Dimension \n",
    "***\n",
    "\n",
    "**Name**: \n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Wednesday April 18th**. Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**.  For a refresher on the course **Collaboration Policy** click [here](https://github.com/chrisketelsen/CSCI-4622-Machine-Learning/blob/master/resources/syllabus.md#collaboration-policy).\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T14:42:01.964923Z",
     "start_time": "2018-04-03T14:42:01.249718Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [15 points] Problem 1 - Naive Bayes for Tennis Prediction \n",
    "***\n",
    "\n",
    "Suppose you are trying to learn a person's decision whether to play tennis or not on a given day using features corresponding to precipitation forecast, temperature, humidity, and wind. You're given the following training data: \n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c|c|c|c}\n",
    "\\textbf{Forecast} & \\textbf{Temp} & \\textbf{Humidity} & \\textbf{Wind} & \\textbf{PlayTennis} \\\\\n",
    "\\hline \n",
    "\\textrm{sunny} & \\textrm{hot} & \\textrm{high} & \\textrm{weak} & \\textbf{No} \\\\ \n",
    "\\textrm{sunny} & \\textrm{hot} & \\textrm{high} & \\textrm{strong} & \\textbf{No} \\\\ \n",
    "\\textrm{overcast} & \\textrm{hot} & \\textrm{high} & \\textrm{weak} & \\textbf{Yes} \\\\ \n",
    "\\textrm{rainy} & \\textrm{mild} & \\textrm{high} & \\textrm{weak} & \\textbf{Yes} \\\\ \n",
    "\\textrm{rainy} & \\textrm{cool} & \\textrm{normal} & \\textrm{weak} & \\textbf{Yes} \\\\ \n",
    "\\textrm{rainy} & \\textrm{cool} & \\textrm{normal} & \\textrm{strong} & \\textbf{No} \\\\ \n",
    "\\textrm{overcast} & \\textrm{cool} & \\textrm{normal} & \\textrm{strong} & \\textbf{Yes} \\\\ \n",
    "\\textrm{sunny} & \\textrm{mild} & \\textrm{high} & \\textrm{weak} & \\textbf{No} \\\\ \n",
    "\\textrm{sunny} & \\textrm{cool} & \\textrm{normal} & \\textrm{weak} & \\textbf{Yes} \\\\ \n",
    "\\textrm{rainy} & \\textrm{mild} & \\textrm{normal} & \\textrm{weak} & \\textbf{Yes} \\\\ \n",
    "\\textrm{sunny} & \\textrm{mild} & \\textrm{normal} & \\textrm{strong} & \\textbf{Yes} \\\\ \n",
    "\\textrm{overcast} & \\textrm{mild} & \\textrm{high} & \\textrm{strong} & \\textbf{Yes} \\\\ \n",
    "\\textrm{overcast} & \\textrm{hot} & \\textrm{normal} & \\textrm{weak} & \\textbf{Yes} \\\\ \n",
    "\\textrm{rainy} & \\textrm{mild} & \\textrm{high} & \\textrm{strong} & \\textbf{No} \\\\ \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**Part A**: Estimate the priors $p(\\textrm{PlayTennis=Yes})$ and $p(\\textrm{PlayTennis=No})$ from the training data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "$$p(\\textrm{PlayTennis=Yes}) = \\frac{9}{14}, \\text{because there are 9 yeses out of total 14 of Yes and No} $$\n",
    "$$p(\\textrm{PlayTennis=No}) = \\frac{5}{14} , \\text{because there are 5 Nos out of total 14 of Yes and No} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: For each feature\n",
    "- state the vocabulary $V$ for the feature \n",
    "- estimate the class-conditional probabilities $p(\\textrm{feature value} \\mid \\textrm{PlayTennis})$ from the training data using Laplace add-one smoothing. Show your work. \n",
    "\n",
    "**Note**: There is no need to include any `UNK` features for this data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$X_{f} \\in \\textrm{{sunny, overcast, rainy}} $$\n",
    "$$X_{i} \\in \\textrm{{hot, mild, cool}} $$\n",
    "$$X_{h} \\in \\textrm{{high, normal}} $$\n",
    "$$X_{w} \\in \\textrm{{weak, strong}} $$\n",
    "\n",
    "$$ \\text{Remember that the Laplace Smoothing equation is} $$\n",
    "\n",
    "$$\\hat{p}(\\text{term | Class}) = \\frac{\\# \\text{ instances of term in Class} + 1}{\\# \\textrm{ total Words in Class} + |V|} , \\text{where |V| is how many distinct vocabulary} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{sunny | playtennis = Yes}) = \\frac{2+1}{9+3} = \\frac{3}{12} = \\frac{1}{4} $$\n",
    "$$\\hat{p}(\\textrm{sunny | playtennis = No}) = \\frac{3+1}{5+3} = \\frac{4}{8} = \\frac{1}{2} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{overcast | playtennis = Yes}) = \\frac{4+1}{9+3} = \\frac{5}{12} $$\n",
    "$$\\hat{p}(\\textrm{overcast | playtennis = No}) = \\frac{0+1}{5+3} = \\frac{1}{8} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{rainy | playtennis = Yes}) = \\frac{3+1}{9+3} = \\frac{4}{12} = \\frac{1}{3} $$\n",
    "$$\\hat{p}(\\textrm{rainy | playtennis = No}) = \\frac{2+1}{5+3} = \\frac{3}{8} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{hot | playtennis = Yes}) = \\frac{2+1}{9+3} = \\frac{3}{12} = \\frac{1}{4} $$\n",
    "$$\\hat{p}(\\textrm{hot | playtennis = No}) = \\frac{2+1}{5+3} = \\frac{3}{8} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{mild | playtennis = Yes}) = \\frac{4+1}{9+3} = \\frac{5}{12} $$\n",
    "$$\\hat{p}(\\textrm{mild | playtennis = No}) = \\frac{2+1}{5+3} = \\frac{3}{8} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{cool | playtennis = Yes}) = \\frac{3+1}{9+3} = \\frac{4}{12} = \\frac{1}{3} $$\n",
    "$$\\hat{p}(\\textrm{cool | playtennis = No}) = \\frac{1+1}{5+3} = \\frac{2}{8} = \\frac{1}{4}$$\n",
    "\n",
    "$$\\hat{p}(\\textrm{high | playtennis = Yes}) = \\frac{3+1}{9+2} = \\frac{4}{11} $$\n",
    "$$\\hat{p}(\\textrm{high | playtennis = No}) = \\frac{4+1}{5+2} = \\frac{5}{7} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{normal | playtennis = Yes}) = \\frac{6+1}{9+2} = \\frac{7}{11} $$\n",
    "$$\\hat{p}(\\textrm{normal | playtennis = No}) = \\frac{1+1}{5+2} = \\frac{2}{7} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{weak | playtennis = Yes}) = \\frac{6+1}{9+2} = \\frac{7}{11} $$\n",
    "$$\\hat{p}(\\textrm{weak | playtennis = No}) = \\frac{2+1}{5+2} = \\frac{3}{7} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{strong | playtennis = Yes}) = \\frac{3+1}{9+2} = \\frac{4}{11} $$\n",
    "$$\\hat{p}(\\textrm{strong | playtennis = No}) = \\frac{3+1}{5+2} = \\frac{4}{7} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: What would your Naive Bayes model predict for the following two weather conditions. Show all work.  \n",
    "- **Forecast**=overcast, **Temp**=cool, **Humidity**=high, **Wind**=weak  \n",
    "- **Forecast**=sunny, **Temp**=hot, **Humidity**=normal, **Wind**=strong  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$x=[\\text{overcast, cool, high, weak}]$$\n",
    "$$\\hat{p}(\\textrm{overcast | playtennis = Yes}) = \\frac{4+1}{9+3} = \\frac{5}{12} $$\n",
    "$$\\hat{p}(\\textrm{overcast | playtennis = No}) = \\frac{0+1}{5+3} = \\frac{1}{8} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{cool | playtennis = Yes}) = \\frac{3+1}{9+3} = \\frac{4}{12} = \\frac{1}{3} $$\n",
    "$$\\hat{p}(\\textrm{cool | playtennis = No}) = \\frac{1+1}{5+3} = \\frac{2}{8} = \\frac{1}{4}$$\n",
    "\n",
    "$$\\hat{p}(\\textrm{high | playtennis = Yes}) = \\frac{3+1}{9+2} = \\frac{4}{11} $$\n",
    "$$\\hat{p}(\\textrm{high | playtennis = No}) = \\frac{4+1}{5+2} = \\frac{5}{7} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{weak | playtennis = Yes}) = \\frac{6+1}{9+2} = \\frac{7}{11} $$\n",
    "$$\\hat{p}(\\textrm{weak | playtennis = No}) = \\frac{2+1}{5+2} = \\frac{3}{7} $$\n",
    "\n",
    "$$\\text{For Yes: } \\frac{5}{12} \\times \\frac{1}{3} \\times \\frac{4}{11} \\times \\frac{7}{11} \\times \\frac{5}{8}= 0.0201$$\n",
    "$$\\text{For No: } \\frac{1}{8} \\times \\frac{1}{4} \\times \\frac{5}{7} \\times \\frac{3}{7} \\times \\frac{3}{8}= 0.003587372$$\n",
    "$$\\text{Yea is higher than No, so we predict Yes}$$\n",
    "\n",
    "$$x=[\\text{sunny, hot, normal, strong}]$$\n",
    "$$\\hat{p}(\\textrm{sunny | playtennis = Yes}) = \\frac{2+1}{9+3} = \\frac{3}{12} = \\frac{1}{4} $$\n",
    "$$\\hat{p}(\\textrm{sunny | playtennis = No}) = \\frac{3+1}{5+3} = \\frac{4}{8} = \\frac{1}{2} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{hot | playtennis = Yes}) = \\frac{2+1}{9+3} = \\frac{3}{12} = \\frac{1}{4} $$\n",
    "$$\\hat{p}(\\textrm{hot | playtennis = No}) = \\frac{2+1}{5+3} = \\frac{3}{8} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{normal | playtennis = Yes}) = \\frac{6+1}{9+2} = \\frac{7}{11} $$\n",
    "$$\\hat{p}(\\textrm{normal | playtennis = No}) = \\frac{1+1}{5+2} = \\frac{2}{7} $$\n",
    "\n",
    "$$\\hat{p}(\\textrm{strong | playtennis = Yes}) = \\frac{3+1}{9+2} = \\frac{4}{11} $$\n",
    "$$\\hat{p}(\\textrm{strong | playtennis = No}) = \\frac{3+1}{5+2} = \\frac{4}{7} $$\n",
    "\n",
    "$$\\text{For Yes: } \\frac{1}{4} \\times \\frac{1}{4} \\times \\frac{7}{11} \\times \\frac{4}{11} \\times \\frac{5}{8}= 0.009039256$$\n",
    "$$\\text{For No: } \\frac{1}{2} \\times \\frac{3}{8} \\times \\frac{2}{7} \\times \\frac{4}{7} \\times \\frac{3}{8}= 0.011479592$$\n",
    "$$\\text{No is higher than Yes, so we predict No}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [35 points] Problem 2 - Implementing Discrete Naive Bayes for Text Classification \n",
    "***\n",
    "\n",
    "In this problem you'll implement a general Discrete Naive Bayes class for text classification. Your tasks will be to implement `train`, `predict_log_score`, and `predict` routines to learn the Naive Bayes model parameters from a collection on text and make predictions on unseen validation data. \n",
    "\n",
    "The skeleton for the `TextNB` class is below. Note that this class is fairly similar to the one you worked with in the Hands-On Naive Bayes in-class notebook, so you should look there to remind yourself of the details. Scroll down to find more information about your tasks as well as unit tests.\n",
    "\n",
    "**Important Note**: In Problem 3 we'll be using the `TextNB` class to make predictions about Twitter data.  Since real-world text data typically has a large number of features, you'll want to make your implementation reasonably efficient so that your experiments in Problem 3 don't take forever. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T14:42:09.159492Z",
     "start_time": "2018-04-03T14:42:09.076713Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TextNB:\n",
    "    def __init__(self, text_train, y_train, alpha=1.0):\n",
    "        \"\"\"\n",
    "        :param text_train: a list or ndarray of text strings to use as training data \n",
    "        :param y_train: an ndarray of true labels associated with the text data \n",
    "        :param alpha: the Laplace smoothing parameter \n",
    "        \"\"\"\n",
    "        \n",
    "        # store training data \n",
    "        self.text_train = text_train \n",
    "        self.y_train = y_train \n",
    "        \n",
    "        # store smoothing parameter\n",
    "        self.alpha = alpha \n",
    "        \n",
    "        # get number of classes\n",
    "#         print(\"Haha: \",len(set(y_train)))\n",
    "        self.num_classes = len(set(y_train))\n",
    "        \n",
    "        # initialize vocab to feature map \n",
    "        self.vocab = dict() \n",
    "        \n",
    "        # initialize class counts \n",
    "        self.class_counts = np.zeros(self.num_classes, dtype=int)\n",
    "        \n",
    "        # initialize feature counts (Note, will need to update this with the correct\n",
    "        # number of columns during the training process)\n",
    "        self.feature_counts = np.zeros((self.num_classes, 0), dtype=int)\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Learn the vocabularly, class_counts, and feature counts from the training data \n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO \n",
    "        A = set()\n",
    "        \n",
    "        for StringText in self.text_train:\n",
    "            for eachVoca in StringText.split(' '):\n",
    "                if len(eachVoca) > 0:\n",
    "                    A.add(eachVoca)\n",
    "#                 print(A)\n",
    "\n",
    "        self.vocab = dict(zip(list(A), range(len(A))))\n",
    "#         print(self.vocab)\n",
    "        \n",
    "        # populate the counts array \n",
    "#         vals, self.class_counts = np.unique(self.y_train, return_counts = True)\n",
    "        self.class_counts = np.array([np.sum(self.y_train == ii) for ii in range(self.num_classes)])\n",
    "        \n",
    "        # populate priors \n",
    "        self.priors = np.array([(self.class_counts[ii] + self.alpha )/ (np.sum(self.class_counts) + self.alpha * self.num_classes ) for ii in range(self.num_classes)])\n",
    "                    \n",
    "        # initialize feature counts \n",
    "        self.feature_counts = np.zeros((self.num_classes, len(self.vocab)), dtype=int)\n",
    "                    \n",
    "        for StringText, y_train_c in zip (self.text_train, self.y_train):\n",
    "            for eachVoca in StringText.split(' '):\n",
    "                if len(eachVoca) > 0:\n",
    "                    self.feature_counts[y_train_c, self.vocab[eachVoca]] += 1\n",
    "                    \n",
    "    def predict_log_score(self, text_str):\n",
    "        \"\"\"\n",
    "        Get the log-probability score for each class\n",
    "        for a query string\n",
    "        \n",
    "        :param text_str: a single string of text to compute the log_score for \n",
    "        \"\"\"\n",
    "        \n",
    "        # p(0|x) is propotional to p(x_1|0) * p(X_2|0) * p(0)\n",
    "        # log(p(x_1|0)) + log(p(X_2|0)) + log(p(0))\n",
    "        \n",
    "        # 1st features: x[0]\n",
    "        # 2nd class c = 1\n",
    "        \n",
    "        # TODO \n",
    "        \n",
    "        # class likelihood\n",
    "        class_scores = np.zeros(self.num_classes)\n",
    "        \n",
    "        for c in range(self.num_classes):\n",
    "            class_scores[c] += np.log(self.priors[c])\n",
    "            \n",
    "            for eachVoca in text_str.split(' '):\n",
    "                if len(eachVoca) > 0 and eachVoca in self.vocab:\n",
    "#                     print(eachVoca)\n",
    "                    class_scores[c] += np.log( (self.feature_counts[c, self.vocab[eachVoca]] + self.alpha) / (np.sum(self.feature_counts[c]) + self.alpha * len(self.vocab)) )\n",
    "        \n",
    "        return class_scores\n",
    "        \n",
    "    \n",
    "    def predict(self, text_list):\n",
    "        \"\"\"\n",
    "        Predict the class of each example in text_list  \n",
    "        \n",
    "        :param text_list: a list or ndarray of text strings to make predictions on \n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO \n",
    "        \n",
    "        yhat = np.zeros(len(text_list), dtype=int)\n",
    "        \n",
    "        for ii, x in enumerate(text_list):\n",
    "            class_scores = self.predict_log_score(x)\n",
    "            yhat[ii] = np.argmax(class_scores)\n",
    "        \n",
    "        return yhat \n",
    "        \n",
    "        \n",
    "    def accuracy(self, text_list, y_true):\n",
    "        \"\"\"\n",
    "        Make predictions on texts in text_list and compute accuracy relative to \n",
    "        true labels in y_true \n",
    "        \n",
    "        :param text_list: a list or ndarray of text strings to make predictions on \n",
    "        :param y_list: an ndarray of true labels associated with the text data \n",
    "        \"\"\"\n",
    "        yhat = self.predict(text_list)\n",
    "        return np.sum(yhat == y_true)/len(y_true)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Complete the `train` function in the `TextNB` class to prepare to make Naive Bayes predictions using Laplace smoothing.  In this routine you will need to populate the following data structures: \n",
    "\n",
    "`self.vocab`: A Python dictionary that maps distinct terms found in the training set to unique indices in $\\{0, 1, \\ldots, |V|-1\\}$.  This will allow us to quickly look up frequency counts for an encountered term in a Numpy array. Note that while the data is fairly clean (We've removed punctuation and made all characters lowercase) you should take care that you're not accidentally counting whitespace in the vocabulary. \n",
    "\n",
    "`self.class_counts`: A 1D Numpy array of length `self.num_classes` which counts the number of documents in the training set that belong to each class. \n",
    "\n",
    "`self.feature_counts`: A 2D Numpy array of dimensions `self.num_classes` $\\times$ $|V|$. The $(c,k)$-entry in this array should be the number of times that term $k$ appears in documents belonging to class $c$. Note that we're using the Bag-of-Words approach here, so if a term appears multiple times in a single document, each instance of that term should be counted.  \n",
    "\n",
    "When you think you're done, execute the following unit test, corresponding to the example starting on Slide 29 of [Lecture 24](https://www.cs.colorado.edu/~ketelsen/files/courses/csci4622/slides/lesson24.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T14:45:46.325834Z",
     "start_time": "2018-04-03T14:45:46.314267Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testVocab (__main__.TestNB) ... ok\n",
      "testClassCounts (__main__.TestNB) ... ok\n",
      "testFeatureCounts (__main__.TestNB) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.006s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run -i tests/tests.py \"prob 2A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Complete the `predict_log_score` function in the `TextNB` class to take in a single string of text and compute the associated log-score for each class. For now, you should use add-one Laplace smoothing for both the class-priors and the class-conditional probabilities.  In **Problem 3** we'll experiment with different variants of Laplace smoothing, so if you like you can read ahead now and implement the general version of Laplace smoothing from the beginning.  \n",
    "\n",
    "**Note**: For simplicity and testing purposes, do not implement an `UNK` feature.  Instead, if you encounter a term not in the vocabulary you can safely ignore it. \n",
    "\n",
    "When you think your `predict_log_score` function is working well, execute the following unit test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T14:45:47.998683Z",
     "start_time": "2018-04-03T14:45:47.990764Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testLogScore (__main__.TestNB) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run -i tests/tests.py \"prob 2B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Finally, implement the `predict` method to take in a list or ndarray of text data, call `predict_log_score`, and return a vector of predicted labels. \n",
    "\n",
    "When you think you're done, execute the following unit test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T14:45:49.228361Z",
     "start_time": "2018-04-03T14:45:49.220931Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testPredict (__main__.TestNB) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run -i tests/tests.py \"prob 2C\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [30 points] Problem 3: Predicting the Sentiment of Tweets sent from Passengers to Airlines \n",
    "***\n",
    "\n",
    "In this problem you'll use the `TextNB` class you wrote in **Problem 2** to make predictions about the sentiment of tweets sent by passengers to airlines.  Execute the following cell to load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T14:45:55.395606Z",
     "start_time": "2018-04-03T14:45:55.371833Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('data/airline_tweets.pklz','rb')\n",
    "text_train, y_train, text_valid, y_valid, text_all, y_all = pickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Explore the data and answer the following questions: \n",
    "\n",
    "- How many total examples are there in the training and validation sets? \n",
    "- Which binary label ($\\{0,1\\}$) corresponds to tweets with positive and negative sentiment, respectively?\n",
    "- What percentage of tweets in the training set have true positive sentiment? \n",
    "- What percentage of tweets in the validation set have true positive sentiment? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(text_train)) # how many rows in training set\n",
    "print(len(text_valid)) # how many rows in validation set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{There are 4000 examples in the training and there are 4000 examples in validation sets} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    3    6   24   25   34   37   42   45   47   52   59   66   68\n",
      "   70   71   72   93   98  101  111  117  122  137  147  152  160  161\n",
      "  164  167  172  175  179  189  190  191  192  194  199  206  210  213\n",
      "  214  215  219  223  229  232  233  237  238  239  240  242  243  250\n",
      "  255  257  258  259  261  262  265  270  274  275  277  278  282  285\n",
      "  290  291  293  294  295  300  301  304  309  311  324  331  334  347\n",
      "  352  359  362  363  366  374  377  382  387  388  395  402  404  406\n",
      "  412  416  419  421  422  425  426  430  431  433  438  444  447  448\n",
      "  456  457  486  490  493  498  499  500  507  511  514  526  531  533\n",
      "  536  537  538  539  545  547  556  558  561  564  598  603  607  608\n",
      "  610  620  622  623  627  629  630  631  635  636  640  650  652  654\n",
      "  657  661  665  668  669  670  674  679  685  687  691  694  698  699\n",
      "  701  708  713  714  727  728  733  736  739  741  749  756  759  760\n",
      "  761  773  775  779  780  782  786  792  794  795  798  799  801  802\n",
      "  803  805  810  816  820  822  823  824  828  829  832  833  836  839\n",
      "  840  842  844  846  847  852  853  857  858  864  866  870  871  872\n",
      "  874  878  885  887  889  893  896  900  902  904  905  906  911  912\n",
      "  919  926  929  935  936  945  952  957  958  967  968  977  978  982\n",
      "  991  997 1008 1009 1015 1017 1021 1024 1031 1035 1036 1046 1054 1063\n",
      " 1064 1066 1069 1070 1074 1075 1076 1078 1080 1083 1086 1087 1090 1094\n",
      " 1095 1097 1098 1102 1105 1107 1111 1114 1117 1124 1128 1129 1139 1143\n",
      " 1144 1154 1160 1161 1168 1170 1176 1177 1191 1192 1194 1203 1206 1213\n",
      " 1215 1218 1221 1223 1224 1228 1231 1238 1242 1252 1253 1260 1264 1267\n",
      " 1269 1272 1277 1279 1281 1283 1290 1300 1307 1312 1325 1332 1333 1339\n",
      " 1341 1345 1351 1353 1357 1373 1377 1379 1380 1381 1382 1385 1388 1389\n",
      " 1390 1393 1399 1400 1406 1411 1416 1420 1423 1427 1434 1437 1439 1443\n",
      " 1445 1449 1450 1455 1461 1465 1467 1473 1474 1483 1486 1492 1493 1497\n",
      " 1501 1506 1509 1513 1514 1518 1519 1522 1526 1527 1530 1532 1534 1537\n",
      " 1541 1546 1550 1552 1554 1559 1560 1565 1566 1570 1572 1575 1579 1582\n",
      " 1585 1587 1588 1603 1605 1607 1612 1614 1616 1617 1623 1625 1627 1631\n",
      " 1633 1637 1638 1648 1654 1661 1662 1672 1673 1675 1680 1687 1688 1689\n",
      " 1690 1699 1703 1704 1705 1706 1708 1714 1717 1718 1726 1727 1736 1737\n",
      " 1739 1743 1747 1753 1757 1764 1766 1767 1782 1790 1794 1797 1800 1804\n",
      " 1806 1812 1819 1820 1821 1824 1830 1833 1837 1841 1847 1848 1853 1856\n",
      " 1859 1860 1864 1868 1873 1875 1879 1884 1886 1895 1896 1899 1902 1908\n",
      " 1912 1915 1916 1917 1918 1920 1929 1938 1952 1953 1956 1958 1962 1963\n",
      " 1968 1969 1971 1975 1979 1987 1988 1992 1995 1996 1999 2001 2007 2013\n",
      " 2019 2022 2023 2027 2029 2035 2036 2038 2039 2040 2041 2043 2045 2046\n",
      " 2049 2054 2058 2060 2063 2065 2066 2070 2074 2080 2092 2093 2095 2100\n",
      " 2106 2113 2117 2122 2135 2138 2145 2154 2158 2159 2160 2167 2169 2174\n",
      " 2176 2177 2184 2189 2193 2198 2199 2202 2207 2208 2209 2214 2217 2218\n",
      " 2222 2223 2224 2225 2232 2242 2244 2246 2247 2251 2255 2257 2258 2261\n",
      " 2269 2276 2283 2287 2288 2289 2294 2296 2299 2302 2303 2306 2309 2315\n",
      " 2316 2319 2324 2328 2340 2341 2342 2359 2364 2369 2372 2373 2382 2394\n",
      " 2396 2403 2415 2428 2429 2447 2449 2450 2452 2456 2459 2462 2466 2468\n",
      " 2474 2480 2483 2488 2494 2497 2501 2505 2506 2509 2517 2520 2521 2529\n",
      " 2532 2533 2542 2544 2545 2546 2549 2553 2571 2588 2595 2597 2598 2599\n",
      " 2600 2601 2604 2605 2624 2627 2628 2630 2648 2662 2663 2674 2688 2695\n",
      " 2704 2709 2710 2717 2720 2722 2723 2724 2725 2726 2741 2743 2747 2756\n",
      " 2763 2767 2769 2772 2773 2779 2780 2784 2786 2788 2792 2803 2804 2807\n",
      " 2809 2814 2818 2820 2832 2833 2835 2842 2845 2846 2847 2857 2859 2865\n",
      " 2880 2885 2886 2887 2888 2892 2894 2902 2903 2908 2910 2913 2914 2938\n",
      " 2940 2949 2956 2959 2960 2964 2965 2966 2969 2973 2978 2979 2987 2988\n",
      " 2990 2991 2994 2996 2998 3001 3003 3004 3008 3009 3011 3013 3014 3017\n",
      " 3021 3023 3033 3040 3042 3044 3048 3049 3054 3057 3067 3070 3077 3083\n",
      " 3092 3095 3096 3098 3102 3104 3108 3111 3112 3113 3114 3115 3117 3121\n",
      " 3124 3128 3133 3134 3138 3139 3142 3151 3154 3156 3171 3173 3176 3177\n",
      " 3180 3181 3189 3193 3197 3201 3203 3205 3215 3216 3220 3226 3231 3232\n",
      " 3234 3235 3237 3246 3255 3258 3262 3266 3277 3280 3281 3286 3287 3289\n",
      " 3291 3297 3309 3310 3315 3316 3317 3319 3322 3324 3326 3328 3333 3334\n",
      " 3335 3336 3337 3341 3345 3354 3355 3362 3363 3379 3383 3397 3398 3401\n",
      " 3417 3422 3428 3432 3433 3439 3446 3449 3455 3458 3470 3475 3480 3483\n",
      " 3485 3500 3506 3511 3522 3527 3535 3539 3545 3547 3548 3549 3550 3557\n",
      " 3561 3562 3563 3565 3570 3572 3583 3592 3603 3607 3612 3621 3624 3628\n",
      " 3629 3630 3634 3640 3641 3642 3644 3645 3647 3666 3667 3674 3683 3685\n",
      " 3686 3687 3691 3694 3698 3706 3707 3711 3712 3717 3718 3724 3732 3735\n",
      " 3738 3741 3742 3746 3753 3756 3759 3761 3765 3766 3767 3770 3771 3773\n",
      " 3778 3779 3782 3786 3791 3793 3796 3798 3799 3806 3814 3815 3818 3823\n",
      " 3824 3829 3830 3833 3834 3835 3837 3838 3839 3843 3846 3851 3854 3856\n",
      " 3859 3866 3867 3868 3875 3876 3878 3881 3892 3903 3916 3918 3922 3924\n",
      " 3927 3930 3939 3940 3944 3948 3952 3954 3957 3959 3961 3962 3963 3967\n",
      " 3969 3970 3971 3977 3989 3994]\n"
     ]
    }
   ],
   "source": [
    "print(np.where(y_train == 1)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{All the values above are the indices of y_train that has positive sentiment}$$\n",
    "$$\\text{because they all have 1 at the end of tweet}$$\n",
    "$$\\text{An example of it would be when the index is 3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@jetblue hopefully now my for jetblue will finally go through the 1\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "print(text_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    4 ... 3997 3998 3999]\n"
     ]
    }
   ],
   "source": [
    "print(np.where(y_train == 0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{In this case, all the values above is negative, and label 0 at the end of tweet}$$\n",
    "$$\\text{An example of this when index is 2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@usairways 45 minute delay for take off and 30 minute wait for checked bags really 0\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "print(text_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(text_train[1])\n",
    "# print(np.where(text_train == 1))\n",
    "# print(len(np.where(text_train == 1)[0]))\n",
    "# print(len(np.where(y_train == 1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of true negative sentiment is: 25.0\n"
     ]
    }
   ],
   "source": [
    "# anywhere in the training data that is positive \n",
    "# print(\"The percentage of true positive sentiment is: {:}\".format(len(np.where(text_train == 1)[0]) / len(text_train) * 100))\n",
    "\n",
    "print(\"The percentage of true negative sentiment is: {:}\".format(len(np.where(y_train == 1)[0]) / len(y_train) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(np.where(y_valid == 1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage in the y validation of true negative sentiment is: 23.075000000000003\n"
     ]
    }
   ],
   "source": [
    "# anywhere in the validation set data that is positive \n",
    "# print(\"The percentage in the text validation of true positive sentiment is: {:}\".format(len(np.where(text_valid == 1)[0]) / len(text_valid) * 100))\n",
    "\n",
    "print(\"The percentage in the y validation of true negative sentiment is: {:}\".format(len(np.where(y_valid == 1)[0]) / len(y_valid) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use your `TextNB` class to learn a Naive Bayes classifier for the airline Twitter data.  What accuracy do you achieve on the training set and what accuracy do you achieve on the test set? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is: 0.93470\n",
      "The accuracy on the validation set is: 0.95059\n"
     ]
    }
   ],
   "source": [
    "AirlineTwitterTrain = TextNB(text_train, y_train)\n",
    "AirlineTwitterTrain.train()\n",
    "\n",
    "print(\"The accuracy on the training set is: {:.5f}\".format(AirlineTwitterTrain.accuracy(text_train, y_train)))\n",
    "\n",
    "AirlineTwitterValid = TextNB(text_valid, y_valid)\n",
    "AirlineTwitterValid.train()\n",
    "\n",
    "print(\"The accuracy on the validation set is: {:.5f}\".format(AirlineTwitterValid.accuracy(text_valid, y_valid)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Notice that if we want to make improvements in our Naive Bayes classifier, we don't really have a lot of knobs to turn aside from changing the word features that we use.  One place that we might make some gains though is in using a slightly different version of Laplace smoothing.  \n",
    "\n",
    "Recall that in add-one smoothing we add a $1$ to the numerator in both the estimation of the prior probabilities and the class-conditional likelihoods. \n",
    "\n",
    "$$\n",
    "\\hat{p}(\\textrm{Class}) = \\dfrac{\\textrm{# docs from Class}+1}{\\textrm{# total docs in training data} + |C|},\n",
    "\\quad \\quad\n",
    "\\hat{p}(\\textrm{term} \\mid \\textrm{Class}) = \\dfrac{\\textrm{# instance of term in Class}+1}{\\textrm{# total words in Class} + |V|}\n",
    "$$\n",
    "\n",
    "It turns out there's nothing sacred about adding $1$ to the numerators.  In fact, we can add any positive value $\\alpha$ that we like \n",
    "\n",
    "$$\n",
    "\\hat{p}(\\textrm{Class}) = \\dfrac{\\textrm{# docs from Class}+\\alpha}{\\textrm{# total docs in training data} + ?},\n",
    "\\quad \\quad\n",
    "\\hat{p}(\\textrm{term} \\mid \\textrm{Class}) = \\dfrac{\\textrm{# instance of term in Class}+\\alpha}{\\textrm{# total words in Class} + ?}\n",
    "$$\n",
    "\n",
    "Explain what modification must be made to the denominators so that theses estimates remain valid probabilities. Clearly justify your reasoning. \n",
    "\n",
    "Support this modification in your `TextNB` class above, if you have not already.  Make sure that your code still passes then unit tests when $\\alpha = 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the first one\n",
    "$$\n",
    "\\hat{p}(\\textrm{Class}) = \\dfrac{\\textrm{# docs from Class}+\\alpha}{\\textrm{# total docs in training data} + ?}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\\text{The sum of probability is 1, it can't be more than 1}$$\n",
    "$$\\text{If we sum up all prior probabilities with } \\alpha = 2$$\n",
    "$$\\text{The question mark would be the value of } \\alpha \\text{ which is 2 multiply the number of } \\alpha$$\n",
    "$$\\text{Considering an example that if } \\alpha \\text{ is 2, and we have 3 things}$$\n",
    "$$\\frac{2+2}{8+x}, \\frac{3+2}{8+x}, \\frac{3+2}{8+x}$$\n",
    "$$\\text{Then, if we sum them up, we should get 1 because it's probability. It cannot be greater than 1, so}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{(2+2+3+2+3+2)}{8+x}$$\n",
    "$$\\text{Considering if we rearrange it to become}$$\n",
    "$$\\frac{(2+3+3)+(2+2+2)}{8+x}$$\n",
    "$$\\text{We have amount 3 of } \\alpha \\text{ and multiply the value of } \\alpha \\text{ which is 2 that is 3 $\\cdot$ 2 = 6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second one\n",
    "$$\n",
    "\\hat{p}(\\textrm{term} \\mid \\textrm{Class}) = \\dfrac{\\textrm{# instance of term in Class}+\\alpha}{\\textrm{# total words in Class} + ?}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Consider the following example:}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c|c}\n",
    "\\textbf{HAM} & \\textbf{SPAM} \\\\\n",
    "\\hline \n",
    "\\textrm{work} & \\textrm{fly}  \\\\ \n",
    "\\textrm{money} & \\textrm{buy}  \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say $\\alpha$ is 2 so,\n",
    "\n",
    "$\\hat{p}$(work | HAM) = $\\frac{1+2}{2+x}$\n",
    "\n",
    "$\\hat{p}$(fly | HAM) = $\\frac{1+2}{2+x}$\n",
    "\n",
    "$\\hat{p}$(buy | HAM) = $\\frac{0+2}{2+x}$\n",
    "\n",
    "$\\hat{p}$(money | HAM) = $\\frac{0+2}{2+x}$\n",
    "\n",
    "If we sum them up, we get $\\frac{1+2}{2+x}$ + $\\frac{1+2}{2+x}$ + $\\frac{0+2}{2+x}$ + $\\frac{0+2}{2+x}$\n",
    "\n",
    "If we rearrange the equation like this, $\\frac{(1+1+0+0)+(2+2+2+2)}{2+x}$, since $\\alpha$ = 2, and we have amount 4 of $\\alpha$, so it's 4 $\\cdot$ 2 = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Write some code to perform $K$-Folds cross-validation on the entire data set (`train_all` and `y_all`) to estimate the accuracy of your NB classifier for various values of $\\alpha$ and make a plot showing your results.  \n",
    "\n",
    "To do the partitioning into folds I recommend leveraging sklearn's [StratifiedKFold]() routine.  The documentation demonstrates how it can be used.  \n",
    "\n",
    "For your plot, use at least $K=5$ folds and at least $5$ different values of $\\alpha$ between $0.1$ and $1.5$.  Which value of $\\alpha$ seems to perform the best? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0.100\n",
      "Average accuracy on training set 0.945\n",
      "Average accuracy on validation set 0.912\n",
      "Alpha = 0.256\n",
      "Average accuracy on training set 0.941\n",
      "Average accuracy on validation set 0.914\n",
      "Alpha = 0.411\n",
      "Average accuracy on training set 0.939\n",
      "Average accuracy on validation set 0.914\n",
      "Alpha = 0.567\n",
      "Average accuracy on training set 0.938\n",
      "Average accuracy on validation set 0.913\n",
      "Alpha = 0.722\n",
      "Average accuracy on training set 0.936\n",
      "Average accuracy on validation set 0.912\n",
      "Alpha = 0.878\n",
      "Average accuracy on training set 0.935\n",
      "Average accuracy on validation set 0.912\n",
      "Alpha = 1.033\n",
      "Average accuracy on training set 0.934\n",
      "Average accuracy on validation set 0.911\n",
      "Alpha = 1.189\n",
      "Average accuracy on training set 0.933\n",
      "Average accuracy on validation set 0.910\n",
      "Alpha = 1.344\n",
      "Average accuracy on training set 0.932\n",
      "Average accuracy on validation set 0.910\n",
      "Alpha = 1.500\n",
      "Average accuracy on training set 0.931\n",
      "Average accuracy on validation set 0.910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Validation accuracy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnwAAAFUCAYAAAC++uGQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0b7d4400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train_accuracies = np.zeros(10)\n",
    "valid_accuracies = np.zeros(10)\n",
    "AlphaSets = np.linspace(0.1, 1.5, 10)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "for i, Alpha in enumerate(AlphaSets):\n",
    "    tmp_train_accuracies = np.zeros(5)\n",
    "    tmp_valid_accuracies = np.zeros(5)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits = 5, random_state = 1235, shuffle = True)\n",
    "    j = 0\n",
    "    for train_index, valid_index in skfold.split(text_all, y_all):\n",
    "#     print(\"text: \", train_index, \"test: \", valid_index)\n",
    "        text_train, text_valid = text_all[train_index], text_all[valid_index]\n",
    "        y_train, y_valid = y_all[train_index], y_all[valid_index]\n",
    "        AirlineTwitterTrain = TextNB(text_train, y_train, Alpha)\n",
    "        AirlineTwitterTrain.train()\n",
    "        tmp_train_accuracies[j] = AirlineTwitterTrain.accuracy(text_train, y_train)\n",
    "        tmp_valid_accuracies[j] = AirlineTwitterTrain.accuracy(text_valid, y_valid)\n",
    "        j = j + 1\n",
    "    train_accuracies[i] = np.mean(tmp_train_accuracies)\n",
    "    valid_accuracies[i] = np.mean(tmp_valid_accuracies)\n",
    "    \n",
    "    print(\"Alpha = {:.3f}\".format(Alpha))\n",
    "    print(\"Average accuracy on training set {:.3f}\".format(train_accuracies[i]))\n",
    "    print(\"Average accuracy on validation set {:.3f}\".format(valid_accuracies[i]))\n",
    "\n",
    "#     print(\"The accuracy on the training set is: {:.5f}\".format(AirlineTwitterTrain.accuracy(text_all, y_all)))\n",
    "    \n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (10,5))\n",
    "ax.plot(AlphaSets, valid_accuracies, color='black', marker='o')\n",
    "# ax.grid(Alpha = 0.25)\n",
    "ax.set_title('Accuracy of 5 folds for various alphas', fontsize = 16)\n",
    "ax.set_xlabel('Alpha values', fontsize = 15)\n",
    "ax.set_ylabel('Validation accuracy', fontsize = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Based on the plot, when K folds is 10, looks it performs the best when $\\alpha$ is at 0.4}$$\n",
    "$$$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [20 points] Problem 4: VC Dimension \n",
    "***\n",
    "\n",
    "**Part A**: Consider learning to classify binary labeled data with a single feature $x$.  Let $H$ be the hypothesis class described by the union of two intervals $[a,b] \\cup [c,d]$ such that $h(x)$ labels an example as positive if it's in the interval $[a,b]$ **OR** the interval $[c,d]$.  Determine the VC Dimension of $H$.  Justify your conclusion by demonstrating a shattering of a set $S$ of the appropriate size **AND** by arguing that an arbitrary set consisting of one additional point cannot be shattered by $H$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\text{The VC dimension is 4}$$\n",
    "$$\\text{Suppose we have 4 points, and we can list all possible combinations, there are 16 of them}$$\n",
    "$$$$\n",
    "$$**Step 1**$$\n",
    "\n",
    "$$\\text{Combination} \\quad \\quad \\text{Classifying} $$\n",
    "\n",
    "$$\n",
    "1) \\quad ++++ \\quad  \\quad \\quad [++][++]  \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "2) \\quad +++- \\quad  \\quad \\quad [++][+]- \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "3) \\quad ++-- \\quad  \\quad \\quad [+][+]-- \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "4) \\quad ++-+ \\quad  \\quad \\quad [++]-[+] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "5) \\quad +--+ \\quad  \\quad \\quad [+]--[+] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "6) \\quad +--- \\quad \\quad \\quad [+]---[\\;] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "7) \\quad +-+- \\quad  \\quad \\quad [+]-[+]\\;- \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "8) \\quad +-++ \\quad  \\quad \\quad [+]-[++] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "9) \\quad --++ \\quad  \\quad \\quad --[+][+] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "10) \\quad --+- \\quad  \\quad \\quad --[+]-[\\;] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "11) \\quad ---- \\quad  \\quad \\quad ----[\\;][\\;] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "12) \\quad ---+ \\quad  \\quad \\quad ---[+][\\;] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "13) \\quad -+-+ \\quad  \\quad \\quad -[+]-[+] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "14) \\quad -+-- \\quad  \\quad \\quad [\\;]-[+]-- \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "15) \\quad -++- \\quad  \\quad \\quad -[+][+]- \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "16) \\quad -+++ \\quad  \\quad \\quad -[+][++] \\quad \\checkmark\n",
    "$$\n",
    "$$$$\n",
    "$$**Step 2**$$\n",
    "$$\\text{I argue that an arbitrary set consisting of one additional point cannot be shattered } H, $$\n",
    "$$\\text{because if I have } +-+-+ , \\text{ this will breaks the rule, for example: } [+]-[+]-+$$\n",
    "$$\\text{There is one + that doesn't be classified}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Consider learning to classify binary labeled data with two features, $x_1$ and $x_2$.  Let $H$ be the hypothesis class described by the ability to assign all points in a particular quadrant of the 2D plane to be positive or negative, with the restriction that at least one of the four quadrants must be labeled positive and at least one of the four quadrants must be labeled negative. Determine the VC Dimension of $H$. Again, justify your conclusion by demonstrating a shattering of a set $S$ of the appropriate size **AND** by arguing that an arbitrary set consisting of one additional point cannot be shattered by $H$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Red point indicate +1, blue indicates -1}$$\n",
    "$$\\text{+ sign is positive, cross sign is negative}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABmCAYAAADI1L/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAA21JREFUeJztnU1yskAQhrutb8Uat4E7xAt4Dvde\nIkXhJhuP4DpuPIQeQDyE2Zq12/4WlCZWEvkbhnnj+1RRyEjGlkd6CAyDmpmQsBkNHQCphpIAoCQA\nKAkASgKAkgCgJAAoCQBKAuBfk5XjOLY0TXsK5bE4HA4fZjaus24jSWmaSlEU7aIiN6jqse66jSQh\noKrX13/lvCTbJAAoCQCnkhaLhcvqoHG5LbRJ3p5MJnbvwEFVB28HQmmTqraFqh7MbFKnLqY7ACol\nqepcVQtVLU6n07f3F4uFqOr1F3x5/Yipr69twXTXYxxMdw+EU0l5nrusDhqX28JpuguBUNJdFUx3\nfwxKAoCSAPArab0WSVOR0aicr9deP74VIcRsZrWn5+dna83bm1kUmYl8TlFUljtERK5TZ3qMWUQK\nq7nd/UlKktsve5mSpH2dP+BUUo8xN5HkL929vzcrD4FAYvYn6empWXkIBBKzP0mvryJRdFsWRWV5\nqIQSc928aF3bJLOywU0SM9Vy7vigwcxxm2TWW8zSoE3iaaGB4GmhPwYlAUBJAFASAJQEACUBQEkA\ndO7SRfqnUpKZrcxsYmaT8bjW7TTEMUx3AFASAJQEACUBQEkAUBIAlARA67vPv15cC5VQY2x6MZJ7\nEgCUBEDrdBdq/wGUPg5N4J4EACUBQEkAUBIAlAQAJQFASQBQEgCUBAAlAcAuXQCwSxcATHcAUBIA\nXiWFMLgIIt4Gb1+vReZzkfO5XD4ey2URkdnMVxSYeNuTXl4+BV04n8tych9vkgIZXAQSb5ICGVwE\nEm+SQhlcBBFvkmYzkdVKJElEVMv5asWDhjp4fTTPbEYpbeA/swBQEgCUBAAlAdBZ0nK5lN1ud1O2\n2+1kuVx2rRoap0+9qTswnv0yKOF2u7U4jm273f647BtxPShhhzgq3vc7mvFFTJZlgwoyo6S7w3tm\nWWYiYlmWdfhq3RlSUp7nN59/mfI8/ylO7knck77ANun3OCre9zd4+36/l81mI9PpVEREptOpbDYb\n2e/3XauGhg+5ugPKnX5ORzNmv7vhYb87ALxeqvBByCmuLY3aJFU9icjxS1EsIh+ug/LE0LEnZlYr\nNTWS9O2PVYu6jV9oIMXOs+AAUBIAXSWtnEQxDDCxd2qTiB+Y7gCgJAAoCQBKAoCSAPgPzRx9pRFE\nCaAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112f71128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize=(1.5,1.5))\n",
    "\n",
    "ax.plot([0,8], [4,4], lw=3, color='black') # TODO \n",
    "ax.plot([4,4], [0,8], lw=3, color='black') # TODO \n",
    "\n",
    "# Top right\n",
    "plt.plot([6.3], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Top left\n",
    "plt.plot([1.5], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom left\n",
    "plt.plot([1.5], [1.8], marker='o', markersize=6, color=\"blue\")\n",
    "# Bottom right\n",
    "#plt.plot([1.5], [1.5], marker='o', markersize=6, color=\"blue\")\n",
    "\n",
    "# Quadrants\n",
    "# Top right: quadrant 1\n",
    "plt.plot([7.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "# quadrant 2\n",
    "plt.plot([0.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 3\n",
    "plt.plot([0.5], [0.5], marker='x', markersize=6, color=\"black\")\n",
    "# quadrant 4\n",
    "plt.plot([7.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABmCAYAAADI1L/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAA35JREFUeJztnUFyqkAURe9L/ZFjMxX2EDfgOpy7\niRSFk0xcguPvxEXoAsRFJFMzdvr+gDKJ+UkAwaZvvKeKUjoEnhx5TUPbmLtDxM1d3wGIaiSJAEki\nQJIIkCQCJIkASSJAkgiQJAL+NFl4OBx6mqZXCuW22O/3r+5+X2fZRpLSNEVRFJdFJc4ws+e6yzaS\nxICZvb3/LdclVScRIEkEtJa0WCyw3W7PyrbbLRaLRdtVUzOfz7tbmbvXnh4eHvwzm83Gh8Ohbzab\nL+dDA+Bt6pOq7QMovOZ+by3J/V1MlmW9CnK/UUkAZgAKAMVoNPp2o1mWOQDPsqzdp2tJn5LyPD/b\n/mnK8/yrOHUk3dSR5BWSVCd9H0fF32tLan12t9vtsF6vMZlMAACTyQTr9Rq73a7tqqnJ87yzdZk3\naJWPx2OP/bIQyxUHM9u7+7jOsmrMEiBJBEgSAUElrVZAmgJ3d+XrahVy6xcSQ9B1TwP9h3ZSHf7+\ndR8MypP+0zQYlOVdgi5Pwa8YNEI3ZuuQJOef9TQlycWr/JJOJV0x6CaSgqW7l5dm5VEQSdDBJI1G\nzcqjIJKgg0l6egIGg/OywaAsj5ZYgq6bF71lneRe1rdJ4m5WvnZ90uB+hWt3VwoaDeokXRbqCV0W\n+mVIEgGSRIAkESBJBEgSAZJEQKUkM5uZWWFmxeFwCBGT+ESlJHdfuvvY3cf397V+TiM6RumOAEki\nQJIIkCQCJIkASSJAkgi4+NfnH2+uxUqsMTa9GakjiQBJIuDidBdr/wGWPg5N0JFEgCQRIEkESBIB\nkkSAJBEgSQRIEgGSRIAkEaAuXQSoSxcBSncESBIBYSXFMLoIIeEGb1+tgNkMOB7L+efnch4AptNg\nYTAS7kh6fHwXdOJ4LMvFj4STFMnoIoyEkxTJ6CKMhJMUy+gihISTNJ0CyyWQJIBZ+bpc6qShBmEf\nzTOdSsoFqDFLgCQRIEkESBIBnUrq9MFO5HS5Lzod787Meu9/HUtf8Kp9ofHufhmtJc3nc5jZ2zf4\n9P4WU9+19oXS3RXjULq7ITqV1OWDndjRQ65+IJZ0V0Wn6U797vpH/e4ICHurIgAxp7hLaVQnmdkB\nwPOHoiGA166DCkTfsSfuXis1NZL03z+bFXUrv9hgil3tJAIkiYC2kpadRNEPNLG3qpNEGJTuCJAk\nAiSJAEkiQJII+Ac0/nGlJUI8XgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1127b5128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize=(1.5,1.5))\n",
    "\n",
    "ax.plot([0,8], [4,4], lw=3, color='black') # TODO \n",
    "ax.plot([4,4], [0,8], lw=3, color='black') # TODO \n",
    "\n",
    "# Top right\n",
    "plt.plot([6.3], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Top left\n",
    "plt.plot([1.5], [6.3], marker='o', markersize=6, color=\"blue\")\n",
    "# Bottom left\n",
    "plt.plot([1.5], [1.8], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom right\n",
    "#plt.plot([1.5], [1.5], marker='o', markersize=6, color=\"blue\")\n",
    "\n",
    "# Quadrants\n",
    "# Top right: quadrant 1\n",
    "plt.plot([7.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "# quadrant 2\n",
    "plt.plot([0.5], [7.5], marker='x', markersize=6, color=\"black\")\n",
    "# quadrant 3\n",
    "plt.plot([0.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 4\n",
    "plt.plot([7.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABmCAYAAADI1L/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAA2ZJREFUeJztnTFy6jAURe/L/IqatNh7CBtgHfRs\nIuMxTRqWQB0aFgELwCyCtKSmfb/wkB9+ErBBln3DPTMesMYRD51YkmUhm7tDdJuHtgMQl5EkAiSJ\nAEkiQJIIkCQCJIkASSJAkgj4U+fgfr/vaZo2FMp9sd1u3939scqxtSSlaYqiKK6LSpxgZruqx9aS\nxICZfbz/LeOSapMIkCQCgkqaTqchs6NjNpthvV6fpK3Xa8xms9sydvfK29PTk5+jzK5dAHxssVmt\nVt7v9321Wn27/xkAhVcsd0kKzFFMlmU/CnIPLAnABEABoBgMBl8+LM/zk4I5bnmeB/3yVWlbkrt7\nlmUOwLMs+/EYnUn3dia5JFWmqTYpaO8uz/OQ2dGx2WywXC4xGo0AAKPRCMvlEpvN5qZ8zWtclQ+H\nQ+/6sBDLiIOZbd19WOVYXcwSIEkESBIBcSUtFkCaAg8P5etiEfXjr6ETIVftBnqFLvhZXl/de72y\n13/cer0yPSAI2AVvMmS0dZ10liQ5/bbHLUmuz/MbQkpqMuQ6kuJVd29v9dI7QFdCjidpMKiX3gG6\nEnI8SS8vQK93mtbrlekdpTMhV60X/dY2yb1scZPE3ax8DdxpcA8/dtdUyKjRJmlYqCU0LPTLkCQC\nJIkASSJAkgiQJAIkiYCLksxsYmaFmRX7/T5GTOI/Lkpy97m7D919+PhY6ec0IjCq7giQJAIkiQBJ\nIkCSCJAkAiSJgKt/ff755lpX6WqMdW9G6kwiQJIIuLq66+r8AZY5DnXQmUSAJBEgSQRIEgGSRIAk\nESBJBEgSAZJEgCQRoCldBGhKFwGq7giQJAK0IgoB8RZvXyyAyQQ4HMr93a7cB4DxOFoYjMQ7k56f\n/wk6cjiU6eIsWhGFAK2IQoBWRCEgnqTxGJjPgSQBzMrX+VydhgrEfTTPeCwpV6CLWQIkiQBJIkCS\nCNBDrhoiZFkEXe/OzFqff92VueCXykLr3f0ybpY0nU5hZh//wcf391j1NVUWqu4ajEPV3R2hh1w1\nRMiy0GrGLRG0utO8u/bRvDsC4t6qiECXq7hrqdUmmdkewO5TUh/Ae+igItF27Im7V6qaakn68sdm\nRdXGr2swxa7rJAIkiYBbJc2DRNEONLHf1CaJOKi6I0CSCJAkAiSJAEki4C9cJ3GlhPBo/AAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112a32c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize=(1.5,1.5))\n",
    "\n",
    "ax.plot([0,8], [4,4], lw=3, color='black') # TODO \n",
    "ax.plot([4,4], [0,8], lw=3, color='black') # TODO \n",
    "\n",
    "# Top right: quadrant 1\n",
    "plt.plot([6.3], [6.3], marker='o', markersize=6, color=\"blue\")\n",
    "# Top left: quadrant 2\n",
    "plt.plot([1.5], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom left: quadrant 3\n",
    "plt.plot([1.5], [1.8], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom right: quadrant 4\n",
    "#plt.plot([1.5], [1.5], marker='o', markersize=6, color=\"blue\")\n",
    "\n",
    "# Quadrants\n",
    "# Top right: quadrant 1\n",
    "plt.plot([7.5], [7.5], marker='x', markersize=6, color=\"black\")\n",
    "\n",
    "# quadrant 2\n",
    "plt.plot([0.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 3\n",
    "plt.plot([0.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 4\n",
    "plt.plot([7.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABmCAYAAADI1L/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAA2BJREFUeJztnT1yukAcht/N/Ctq0gp3iBfwHPZe\nIsOQJo1HsI6Nh9ADiIcwraltfykYk5i/keXDhTd5nxnGsCD8zDP7wQK7zswghs1d3wGIaiSJAEki\nQJIIkCQCJIkASSJAkgiQJAL+1dk5jmNL0/RGofwtdrvdm5nd++xbS1KapiiKollU4gzn3N5331qS\nGHDOffz9W/olVScRIEkEtJY0n8+x2WzO0jabDebzedtDU/P09NTdwczMe3l4eLDvrNdri+PY1uv1\nxfXQAPhY+qTq/AAK8/y/t5Zk9ikmy7JeBZn9UUkAZgAKAMVoNPrxpFmWGQDLsqzdr2tJn5LyPD87\n/2nJ8/xSnMpJfyonWYUk1Uk/x1Gx3VtS69bddrvFarXCZDIBAEwmE6xWK2y327aHpibP886O5azG\nVfl4PLahdwux9Dg453ZmNvbZVxezBEgSAZJEQFBJyyWQpsDdXfm5XIY8e0OGELRvM9CuXCf58PJi\nFkVlo/+0RFGZ3iXosgl+w6AR+mLWhyQ5/62nJUkaH/IinUq6YdB1JAUr7l5f66UPgoEEHUzSaFQv\nfRAMJOhgkp6fgSg6T4uiMn2wDCVo33LRWtZJZmV9myRmzpWfXTcazG7Qd3ejoFGjTlK3UE+oW+iX\nIUkESBIBkkSAJBEgSQRIEgGVkpxzM+dc4ZwrDodDiJjENyolmdnCzMZmNr6/93qdRnSMijsCJIkA\nSSJAkgiQJAIkiQBJIqDx2+dfb64NlaHGWPdmpHISAZJEQOPibqjPD7A841AH5SQCJIkASSJAkgiQ\nJAIkiQBJIkCSCJAkAiSJAD3SRYAe6SJAxR0BkkSARkQhINjg7cslMJsBx2O5vt+X6wAwnYaKgpNg\nOenx8VPQieOxTBfX0YgoBGhEFAI0IgoBwSRNp8BiASQJ4Fz5uVio0eBD0Kl5plNJaYIuZgmQJAIk\niQBJIkCTXN0ITXJ1BfzCCUU6GTlSU/NcjqNie/ghpzXJlSa58kY5SXVSrTgqtmuSq77RJFdXYHnT\nr9PRjPXcXf/ouTsCgt6qCMGQi7im1KqTnHMHAPsvSTGAt66DCkTfsSdm5lU01ZL035edK3wrv6HB\nFLt6wQmQJALaSlp0EkU/0MTeqk4SYVBxR4AkESBJBEgSAZJEwDtBvIdJOfQhiAAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112f1ea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize=(1.5,1.5))\n",
    "\n",
    "ax.plot([0,8], [4,4], lw=3, color='black') # TODO \n",
    "ax.plot([4,4], [0,8], lw=3, color='black') # TODO \n",
    "\n",
    "# Top right: quadrant 1\n",
    "plt.plot([6.3], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Top left: quadrant 2\n",
    "plt.plot([1.5], [6.3], marker='o', markersize=6, color=\"blue\")\n",
    "# Bottom left: quadrant 3\n",
    "plt.plot([1.5], [1.8], marker='o', markersize=6, color=\"blue\")\n",
    "# Bottom right: quadrant 4\n",
    "#plt.plot([1.5], [1.5], marker='o', markersize=6, color=\"blue\")\n",
    "\n",
    "# Quadrants\n",
    "# Top right: quadrant 1\n",
    "plt.plot([7.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "# quadrant 2\n",
    "plt.plot([0.5], [7.5], marker='x', markersize=6, color=\"black\")\n",
    "# quadrant 3\n",
    "plt.plot([0.5], [0.5], marker='x', markersize=6, color=\"black\")\n",
    "# quadrant 4\n",
    "plt.plot([7.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABmCAYAAADI1L/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAA2NJREFUeJztnTty8jAYRa8yf+XaabH3EDbAOujZ\nRMbjNGlYAnVoWAQsALMI0pKa9kvhIYH8JMgv2Te5Z8ZDLBzz4TN6WBaSMzOIYXPXdwDiNpJEgCQR\nIEkESBIBkkSAJBEgSQRIEgH/qhwcx7GladpRKH+L3W73Zmb3PsdWkpSmKYqiqBeVuMA5t/c9tpIk\nBpxzH3//ln5J1UkESBIBjSXN53NsNpuLtM1mg/l83vTUdHR2LczMe3t4eLCvrNdri+PY1uv11f3Q\nAPjYQlPlWgAozPO6N5Z0HkyWZb0KMutXkpn/tWhVEoAZgAJAMRqNvg0uyzIDYFmWtfNta9K3JDO/\na6Gc9Ndykt2QpDrpk67qpMatu+12i9VqhclkAgCYTCZYrVbYbrdNT01HV9fCWYW78vF4bEPvFmLp\ncXDO7cxs7HOsbmYJkCQCJImAoJKWSyBNgbu78nW5DPnp9RhEzL7NQPvhPsmHlxezKCob/actisr0\nNkGLTfAuY0bom1kfkuTyy562JKl9yqu0KanLmKtIClbcvb5WSx8CQ4k5mKTRqFr6EBhKzMEkPT8D\nUXSZFkVl+lAZTMy+5aI1rJPMygo3ScycK1/bbjSYtd9311XMqFAnqVuoJ9Qt9MuQJAIkiQBJIkCS\nCJAkAiSJgJuSnHMz51zhnCsOh0OImMQXbkoys4WZjc1sfH/v9XMa0TIq7giQJAIkiQBJIkCSCJAk\nAiSJgNq/Pj9/uDZUhhpj1YeRykkESBIBtYu7oY4fYBnjUAXlJAIkiQBJIkCSCJAkAiSJAEkiQJII\nkCQCJIkADekiQEO6CFBxR4AkEaAZUQgINnn7cgnMZsDxWO7v9+U+AEynoaLgJFhOenz8FHTieCzT\nxc9oRhQCNCMKAZoRhYBgkqZTYLEAkgRwrnxdLNRo8CHo0jzTqaTUQTezBEgSAZJEgCQRoEWuOuLp\n6am9k/lOjGdaUKRyHDfe19I8knQFLXJlluf5xeeftjzPr8WpnKScdIbqpO/juPG+FrnqmzzPWzuX\nZjPuiVZnM9a4u/7RuDsCgj6qCMGQi7i6VKqTnHMHAPuzpBjAW9tBBaLv2BMz8yqaKkn675+dK3wr\nv6HBFLt6wQmQJAKaSlq0EkU/0MTeqE4SYVBxR4AkESBJBEgSAZJEwDvVd4vqS9g/xgAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112f64550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize=(1.5,1.5))\n",
    "\n",
    "ax.plot([0,8], [4,4], lw=3, color='black') # TODO \n",
    "ax.plot([4,4], [0,8], lw=3, color='black') # TODO \n",
    "\n",
    "# Top right: quadrant 1\n",
    "plt.plot([6.3], [6.3], marker='o', markersize=6, color=\"blue\")\n",
    "# Top left: quadrant 2\n",
    "plt.plot([1.5], [6.3], marker='o', markersize=6, color=\"blue\")\n",
    "# Bottom left: quadrant 3\n",
    "plt.plot([1.5], [1.8], marker='o', markersize=6, color=\"blue\")\n",
    "# Bottom right: quadrant 4\n",
    "#plt.plot([1.5], [1.5], marker='o', markersize=6, color=\"blue\")\n",
    "\n",
    "# Quadrants\n",
    "# Top right: quadrant 1\n",
    "plt.plot([7.5], [7.5], marker='x', markersize=6, color=\"black\")\n",
    "\n",
    "# quadrant 2\n",
    "plt.plot([0.5], [7.5], marker='x', markersize=6, color=\"black\")\n",
    "# quadrant 3\n",
    "plt.plot([0.5], [0.5], marker='x', markersize=6, color=\"black\")\n",
    "# quadrant 4\n",
    "plt.plot([7.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABmCAYAAADI1L/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAA4ZJREFUeJztnT1y6jAUhY8yr3JNWuw9hA2wDno2\nkfGYJg1LoA4Ni4AFYBZBWlLT3ld4yAsvAWQQsk5yvhmPY+GIC9/ox7KRnJlBpM1D1wGIy0gSAZJE\ngCQRIEkESBIBkkSAJBEgSQT8aXNyr9ezoijuFMrvYrPZvJvZo8+5rSQVRYG6rq+LShzhnNv6nttK\nEgPOuY+/f8q4pNokAiSJgKCSJpNJyOzomE6nWK1WR2mr1QrT6fS2jM3Me3t6erJzNNl1C4CPLTbL\n5dJ6vZ4tl8tvjz8DoDbP712SAnMQU5blSUFmgSUBGAOoAdT9fv/Lm1VVdfTFHLaqqoJ+eF+6lmRm\nVpalAbCyLE+eo5L020qSSZI392qTgvbuqqoKmR0d6/Uai8UCw+EQADAcDrFYLLBer2/K11mLq/LB\nYGCpDwuxjDg45zZmNvA5VxezBEgSAZJEQFxJ8zlQFMDDQ7Ofz6O+/TUkEbJvN9A8uuBneX01y7Km\n13/YsqxJDwgCdsHvGTK6uk46S54ff9rDlufX5/kNISXdM+Q2kuJVd29v7dITIJWQ40nq99ulJ0Aq\nIceT9PICZNlxWpY16YmSTMi+9aLd2iaZNS1unps51+wDdxrMwo/d3StktGiTNCzUERoW+mFIEgGS\nRIAkESBJBEgSAZJEwEVJzrmxc652ztW73S5GTOI/Lkoys5mZDcxs8Pjo9XMaERhVdwRIEgGSRIAk\nESBJBEgSAZJEwNW/Pv98cy1VUo2x7c1IlSQCJImAq6u7VJ8fYHnGoQ0qSQRIEgGSRIAkESBJBEgS\nAZJEgCQRIEkESBIBeqSLAD3SRYCqOwIkiYCokpKYXYSQaJO3z+fAeAzs983xdtscA8BoFCsKTqKV\npOfnf4IO7PdNujhPNEmpzC7CSDRJqcwuwkg0ScnMLkJINEmjETCbAXkOONfsZzN1GnyIujTPaCQp\n16CLWQIkiQBJIkCSCLhZ0t0WdiIn6IJfvhPj2YlJCdssohEDJLA0zyGOC6/Hnc3YdzmaGEjSmek9\nfRZ2ikGXktos+KWSpJJ0jNqk03FceD3e5O33WtiJnZALfmk2444IOpuxnrvrHj13R0DUWxUxSLmK\nu5ZWbZJzbgdg+ympB+A9dFCR6Dr23My8qqZWkr78s3O1b+OXGkyxaxScAEki4FZJsyBRdANN7De1\nSSIOqu4IkCQCJIkASSJAkgj4C2jlh0nZaVfAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112ec88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize=(1.5,1.5))\n",
    "\n",
    "ax.plot([0,8], [4,4], lw=3, color='black') # TODO \n",
    "ax.plot([4,4], [0,8], lw=3, color='black') # TODO \n",
    "\n",
    "# Top right: quadrant 1\n",
    "plt.plot([6.3], [6.3], marker='o', markersize=6, color=\"blue\")\n",
    "# Top left: quadrant 2\n",
    "plt.plot([1.5], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom left: quadrant 3\n",
    "plt.plot([1.5], [1.8], marker='o', markersize=6, color=\"blue\")\n",
    "# Bottom right: quadrant 4\n",
    "#plt.plot([1.5], [1.5], marker='o', markersize=6, color=\"blue\")\n",
    "\n",
    "# Quadrants\n",
    "# Top right: quadrant 1\n",
    "plt.plot([7.5], [7.5], marker='x', markersize=6, color=\"black\")\n",
    "\n",
    "# quadrant 2\n",
    "plt.plot([0.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 3\n",
    "plt.plot([0.5], [0.5], marker='x', markersize=6, color=\"black\")\n",
    "# quadrant 4\n",
    "plt.plot([7.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABmCAYAAADI1L/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAA3RJREFUeJztnTFy6jAURe/L/IqatJg9hA2wDno2\nkfGEJg1LoA4Ni4AFYBZBWlLTvl94SEJ+frCxLOuGe2Y8YI3jPHTiJ8kWirk7RNrcdR2AuIwkESBJ\nBEgSAZJEgCQRIEkESBIBkkTAnzoH9/t9Hw6HLYVyW+x2uzd3v69ybC1Jw+EQRVFcF5U4w8z2VY+t\nJYkBM3t//1vuS6pNIkCSCGgsaT6fY7PZnJVtNhvM5/Omp6ajtbpw98rbw8ODf2W9Xnu/3/f1ev3t\nfmwAvG+xqVMXAAqvWO+NJX0OJs/zTgW5dyvJvXpdBJUEYAqgAFAMBoP/BpfnuQPwPM/DfNor6VqS\ne7W60JV0a1eSX5CkNumDttqkxr277XaL1WqF8XgMABiPx1itVthut01PTUdbdWFeY1Q+Go089dtC\nLHcczGzn7qMqx2owS4AkESBJBESVtFwCwyFwd1e+Lpcxf/t1JBFz1W6g/zBOqsLLi3uvV3b6T1uv\nV5aHBAG74G3GjNiD2Spk2fmHPW1ZdvUpvyWkpDZjriMpWrp7fa1XngKpxBxN0mBQrzwFUok5mqTn\nZ6DXOy/r9cryVEkm5qp50Ru2Se5lg5tl7mbla+hOg3v4e3dtxYwabZJuC3WEbgv9MiSJAEkiQJII\nkCQCJIkASSLgoiQzm5pZYWbF4XCIEZP4wkVJ7r5w95G7j+7vK32dRgRG6Y4ASSJAkgiQJAIkiQBJ\nIkCSCLj62+efH66lSqox1n0YqSuJAEki4Op0l+r8AZY5DnXQlUSAJBEgSQRIEgGSRIAkESBJBEgS\nAZJEgCQRoCldBGhKFwFKdwRIEgFxJSWxvAgf8RZvXy6B6RQ4Hsv9/b7cB4DJJFoYjMS7kh4fPwSd\nOB7LcvEj8SSlsrwIIfEkpbK8CCHxJCWzvAgf8SRNJsBiAWQZYFa+LhbqNFQg7r/mmUwk5Qo0mCVA\nkgiQJAIkiYCgkmazWcjTUROyLoKud2dmnc+/TmUu+KW60Hp3v4zGkmazGczs/S/49P4WU19bdaF0\n12IcSnc3RFBJT09PIU9HTci60GrGHRE03WneXfdo3h0BcR9VRCDlFHcttdokMzsA2H8q6gN4Cx1U\nJLqOPXP3SqmplqR/ftisqNr4pQZT7BonESBJBDSVtAgSRTfQxN6oTRJxULojQJIIkCQCJIkASSLg\nL8i5dkbD/zMUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11319fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize=(1.5,1.5))\n",
    "\n",
    "ax.plot([0,8], [4,4], lw=3, color='black') # TODO \n",
    "ax.plot([4,4], [0,8], lw=3, color='black') # TODO \n",
    "\n",
    "# Top right: quadrant 1\n",
    "plt.plot([6.3], [6.3], marker='o', markersize=6, color=\"blue\")\n",
    "# Top left: quadrant 2\n",
    "plt.plot([1.5], [6.3], marker='o', markersize=6, color=\"blue\")\n",
    "# Bottom left: quadrant 3\n",
    "plt.plot([1.5], [1.8], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom right: quadrant 4\n",
    "#plt.plot([1.5], [1.5], marker='o', markersize=6, color=\"blue\")\n",
    "\n",
    "# Quadrants\n",
    "# Top right: quadrant 1\n",
    "plt.plot([7.5], [7.5], marker='x', markersize=6, color=\"black\")\n",
    "\n",
    "# quadrant 2\n",
    "plt.plot([0.5], [7.5], marker='x', markersize=6, color=\"black\")\n",
    "# quadrant 3\n",
    "plt.plot([0.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 4\n",
    "plt.plot([7.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABmCAYAAADI1L/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAA19JREFUeJztnT1y8jAQhnczX+XaaWPfIVyAc9Dn\nEhmPadJwBOrQcAg4AOYQpCU17X6Fh7/JD5Yty3rD+8x4jBVHWfTglWMLWc1MSNw8DB0AuQ0lAUBJ\nAFASAJQEACUBQEkAUBIAlATAP5ed0zS1PM97CuW+2G63n2b22GRfJ0l5nktVVe2iIleo6q7pvk6S\nEFDV0+u/cl2SfRIAlASAV0nT6dRnddD4bAt1yduj0ch+O3FQ1cH7gVj6pFttoapbMxs1qYvpDoCb\nklT1RVUrVa32+/2Xn0+nU1HV0yf4+PoeU19fbcF012McTHd3hFdJZVn6rA4an23hNd3FQCzp7hZM\nd38MSgKAkgAIK2mxEMlzkYeHer1YBP3zrYghZjNrvDw/P1tr3t/NksRM5LwkSV3uERE5LZ3pMWYR\nqaxhu4eTlGXXb/a4ZFn7Or/Bq6QeY3aRFC7dfXy4lcdAJDGHk/T05FYeA5HEHE7S25tIklyXJUld\nHiuxxNw0L1rXPsms7nCzzEy1Xns+aTDz3CeZ9RazOPRJvCw0ELws9MegJAAoCQBKAoCSAKAkACgJ\ngM5Dukj/3JRkZnMzG5nZ6PGx0ddpiGeY7gCgJAAoCQBKAoCSAKAkACgJgNbfPr+8uRYrscboejOS\nRxIAlARA63QX6/gBlDEOLvBIAoCSAKAkACgJAEoCgJIAoCQAKAkASgKAkgDgkC4AOKQLAKY7ACgJ\nAM6IAkC4ydsXC5GXF5HDod7e7eptEZHJJFgYiIQ7kl5fz4KOHA51OfkVzogCAGdEAYAzogAQTtJk\nIjKfi2SZiGq9ns950tCAsI/mmUwopQX8ZxYASgKAkgCgJAD4kCuPzGYzWa/XV2Xr9Vpms1m3iptO\njGcNJiUUXxMBdkB8T0rowGq1sjRNbbVafbt9iQw1m/G9SzI7iymK4kdBZoEllWV51TDHpSxLf+/c\ngaElmZkVRWEiYkVR/LgPjyQeST9z75L66pP4kCuPbDYbWS6XMh6PRURkPB7LcrmUzWbTqV7OZjwQ\nXmcz5ri74eG4OwDC3qoIQMwpri1OfZKq7kVkd1GUisin76ACMXTsmZk1Sk1Okr78smrVtPOLDaTY\neRUcAEoCoKukuZcohgEm9k59EgkD0x0AlAQAJQFASQBQEgD/AdgpfaV7/uVzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112f061d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize=(1.5,1.5))\n",
    "\n",
    "ax.plot([0,8], [4,4], lw=3, color='black') # TODO \n",
    "ax.plot([4,4], [0,8], lw=3, color='black') # TODO \n",
    "\n",
    "# Top right: quadrant 1\n",
    "plt.plot([6.3], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Top left: quadrant 2\n",
    "plt.plot([1.5], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom left: quadrant 3\n",
    "plt.plot([1.5], [1.8], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom right: quadrant 4\n",
    "#plt.plot([1.5], [1.5], marker='o', markersize=6, color=\"blue\")\n",
    "\n",
    "# Quadrants\n",
    "# Top right: quadrant 1\n",
    "plt.plot([7.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "# quadrant 2\n",
    "plt.plot([0.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 3\n",
    "plt.plot([0.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 4\n",
    "plt.plot([7.5], [0.5], marker='x', markersize=6, color=\"black\")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{All 3 points correctly classified, what about 4 points?}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABmCAYAAADI1L/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAAxpJREFUeJztnUFyskAQhbutf8Vat8Id9DbuvUQW\nssklWMfb4CHM1qzd9r+g1JikgMFh6Kfvq6LUCSEdPnmjODJqZkJ8M5u6ANINJQFASQBQEgCUBAAl\nAUBJAFASAJQEwL+QlefzuRVFMVIpr8XhcPgys0WfdYMkFUUhdV0Pq4rcoarHvusGSUJAVa/3n+W8\nJPskACgJgKiSyrKMuTloYu4LDcnt9XptbS8cVHXyfsBLn9S1L1T1YGbrPtti3AHQKUlVt6paq2p9\nOp1+/bwsS1HV6zP4cv8Vo2+sfcG4G7EOxt0LEVXSbreLuTloYu6LqHHnAS9x1wXj7smgJAAoCYC0\nkvZ7kaIQmc2a2/0+6Z8fhIeazaz3slqtbDAfH2ZZZiZyW7KsaY+IiFyXhxmxZhGpred+Tycpz+//\n2cuS58O3+QdRJY1Yc4ikdHH3+RnW7gEnNaeTtFyGtXvASc3pJL2/i2TZfVuWNe1e8VJz31y0R/sk\ns6bDzXMz1eY28osGs8h9ktloNUtAn8TTQhPB00JPBiUBQEkAUBIAlAQAJQFASQA8PKSLjE+nJDOr\nzGxtZuvFotfXaUhkGHcAUBIAlAQAJQFASQBQEgCUBMDgb59//3DNK15rDP0wkkcSAJQEwOC48zp+\nAGWMQwg8kgCgJAAoCQBKAoCSAKAkACgJAEoCgJIAoCQAOKQLAA7pAoBxBwAlAcArogCQ7uLt+73I\ndityPjePj8fmsYjIZpOsDETSHUlvbzdBF87npp20wiuidOEgonlFlDYuEX08NlcVukR0YlG8Ikob\nTiI6naTNRqSqRPJcRLW5rSrfLxqcRHTaqXk2G99SfrJcNhH3V3tC+Ga2DScRTUltOInop5uJLDoO\nIppHEgCc5GokOMlVC17GgnPWlxfjYUmc5OoGJ7nqCeOOTAInuRoJTnLVgpe46yJq3HHc3fRw3B0A\nT3fuznPEDSWoT1LVk4h8/4BlLiJfsYtKxNS152bWK5qCJP36ZdW6b+fnDaTa+T4JAEoC4FFJVZQq\npgGm9of6JJIGxh0AlAQAJQFASQBQEgD/AdiniElZw6QYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1130d7668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize=(1.5,1.5))\n",
    "\n",
    "ax.plot([0,8], [4,4], lw=3, color='black') # TODO \n",
    "ax.plot([4,4], [0,8], lw=3, color='black') # TODO \n",
    "\n",
    "# Top right: quadrant 1\n",
    "plt.plot([6.3], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Top left: quadrant 2\n",
    "plt.plot([1.5], [6.3], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom left: quadrant 3\n",
    "plt.plot([1.5], [1.8], marker='o', markersize=6, color=\"red\")\n",
    "# Bottom right: quadrant 4\n",
    "plt.plot([6.3], [1.5], marker='o', markersize=6, color=\"red\")\n",
    "\n",
    "# Quadrants\n",
    "# Top right: quadrant 1\n",
    "plt.plot([7.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "# quadrant 2\n",
    "plt.plot([0.5], [7.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 3\n",
    "plt.plot([0.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "# quadrant 4\n",
    "plt.plot([7.5], [0.5], marker='+', markersize=6, color=\"black\")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{In this example, we can't classify the negative sign in any quadrant.} $$\n",
    "$$\\text{There is no negative quadrant in this graph so we fail to correctly classify. Thus, VC dimenison is 3}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
