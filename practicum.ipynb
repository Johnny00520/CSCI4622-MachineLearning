{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4622 - Spring 2018 - Practicum \n",
    "***\n",
    "\n",
    "\n",
    "This practicum is due on Moodle by **11:59pm on Thursday May 3rd**. \n",
    "\n",
    "**Here are the rules:** \n",
    "\n",
    "4. Your work must be done entirely on your own. You may **NOT** collaborate with classmates or anyone else.  \n",
    "3. You may **NOT** post to message boards or other online resources asking for help. \n",
    "5. You may **NOT** use late days on the practicum nor can you drop your practicum grade. \n",
    "1. You may use your course notes, posted lecture slides, in-class notebooks, and homework solutions as resources. \n",
    "2. You may consult alternate sources like blog posts or technical papers, but you may **NOT** copy code from these sources. \n",
    "3. Any additional non-course sources that you use should be clearly cited (with links) in the **References** section at the bottom of this notebook. \n",
    "7. Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. \n",
    "\n",
    "Violation of the above rules will result in an **F** in the course and a trip to **Honor Council** \n",
    "\n",
    "***\n",
    "\n",
    "**By writing your name below you agree to abide by the given rules:**\n",
    "\n",
    "**Name**: $<$Chen Hao Cheng$>$\n",
    "\n",
    "**Kaggle Username**: $<$insert username here$>$\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- You do not need to implement everything from scratch.  At this point you should be leveraging Sklearn as much as you can. \n",
    "- If you have a clarifying question, please post it as a **PRIVATE** message to me on Piazza. \n",
    "- Part of the goal of this assignment is to see if you can stand on your own.  Please do not ask me to help you debug code or check if your answers are correct. Most of the implementation details necessary to complete this practicum can be found in the Hands-On notebooks or the Sklearn documentation.  \n",
    "- You'll notice that the point totals below do not add up to 100.  This is because 10 out of the 100 points will be attributed to **style**.  To earn full credit for style your analysis should be concise and well-organized, your code should be readable and well-commented, and you should use plots and graphics to support your conclusions whenever appropriate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:17:37.900418Z",
     "start_time": "2018-04-19T11:17:37.897826Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle, gzip \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [35 points] Problem 1: Building Classifiers for Fashion MNIST \n",
    "***\n",
    "\n",
    "The classic MNIST Handwritten Digit data set has been a staple in the machine learning literature since the beginning of time (i.e. the late 90's).  However, machine learning practitioners have grown tired of the rusty digits and have recently begun to create and explore new, more interesting data sets. Some popular alternatives to emerge recently are [EMNIST](https://www.kaggle.com/crawford/emnist), [Sign Language MNIST](https://www.kaggle.com/datamunge/sign-language-mnist), and [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist). In this problem you will explore the latter. \n",
    "\n",
    "Fashion MNIST is comprised of $28 \\times 28$ pixel gray-scale images of clothing, with classes corresponding to things like tops, trousers, coats, dresses, and various types of shoes.  The data set that we'll work with corresponds to a small subset of Fashion MNIST with 1500 examples from each of five distinct classes (tops, trousers, coats, sneakers, and ankle boots). \n",
    "\n",
    "Execute the following cell to load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:16:40.004587Z",
     "start_time": "2018-04-19T11:16:39.285472Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = gzip.open('fashion_mnist_subset.pklz', 'rb')\n",
    "X_all, y_all = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **Parts A-C** you will construct various tuned classifiers for making predictions on Fashion MNIST.  For each classifier you should: \n",
    "- Describe and motivate any transformations on the pixel data that you found helpful/necessary to make your model work well. \n",
    "- Describe and justify your process for determining optimal hyperparameters for each model. Support your decisions with validation studies and associated graphics.  Do **NOT** just report the hyperparameters that worked best.  \n",
    "- Describe how you evaluated your models during your process (i.e. did you use a validation set, did you do cross-validation, etc). \n",
    "- Report the final optimal hyperparameters that you used as well as the accuracy of your final model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Construct a K-Nearest Neighbors classifier to make predictions on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_all)\n",
    "print(y_all)\n",
    "print(len(X_all))\n",
    "print(len(X_all[0]))\n",
    "print(len(y_all))\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, X_train, y_train, K=5, distance_weighted=False):\n",
    "        from sklearn.neighbors import BallTree\n",
    "        self.balltree = BallTree(X_train)\n",
    "        self.y_train = y_train\n",
    "        self.K = K\n",
    "        self.distance_weighted = distance_weighted\n",
    "        \n",
    "    def majority(self, neighbor_indices, neighbor_distances=None):\n",
    "        if self.distance_weighted == False:\n",
    "            import numpy as np\n",
    "            import collections\n",
    "            \n",
    "            Y_trainCounter = collections.Counter(map(lambda x: self.y_train[x], neighbor_indices[0]))\n",
    "            MostCommonCounter = Y_trainCounter.most_common()\n",
    "            \n",
    "            if len(MostCommonCounter) == 1 or MostCommonCounter[0][1] != MostCommonCounter[1][1]: \n",
    "                # return the first element of list [0][0] because it's the most common\n",
    "                return MostCommonCounter[0][0]\n",
    "            else:\n",
    "                # get rid of the last element\n",
    "                return self.majority([neighbor_indices[0][:-1]])\n",
    "            \n",
    "        elif self.distance_weighted == True:\n",
    "            LabelCounter = {}\n",
    "            \n",
    "            for i in range(len(neighbor_indices[0])):\n",
    "                \n",
    "                # Make LabelCounter dict labels = 0, i.e = [-1: 0, 1: 0] depending on the indices of y_train\n",
    "                LabelCounter[self.y_train[neighbor_indices[0][i]]] = 0\n",
    "                \n",
    "#             print(neighbor_indices[0])\n",
    "#             print(\"LabelCounter: \", LabelCounter)\n",
    "            \n",
    "#             print(\"-------------------------------------------------------\")\n",
    "            \n",
    "            for j in range(len(neighbor_indices[0])):\n",
    "                LabelCounter[self.y_train[neighbor_indices[0][j]]] += (1/(neighbor_distances[0][j] + 0.001))\n",
    "#                 print(\"LabelCounterInLoop: \", LabelCounter)\n",
    "#             print(\"New LabelCounter: \", LabelCounter)\n",
    "            WinningClassLabel = max(LabelCounter, key = lambda key: LabelCounter[key])\n",
    "#             print(\"WinningClassLabel: \", WinningClassLabel)\n",
    "            return WinningClassLabel\n",
    "\n",
    "    def classify(self, x):\n",
    "        distance, indices = self.balltree.query(x.reshape(1, -1), self.K)\n",
    "        return self.majority(indices, neighbor_distances = distance)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return list(map(self.classify, X))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictor = KNN(X_all, y_all, 3, False)\n",
    "# yHatValid = predictor.predict(X_all)\n",
    "# print(yHatValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier(15).fit(X_all, y_all)\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# yHat_valid = knn.predict(X_all)\n",
    "# print(yHat_valid)\n",
    "\n",
    "# C = confusion_matrix(y_all, yHat_valid)\n",
    "# print(\"Confusion matrix: \")\n",
    "# print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def view_digit(x, label=None):\n",
    "#     print(\"x is: \", x)\n",
    "\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    plt.imshow(x.reshape(28,28), cmap='gray');\n",
    "    \n",
    "    plt.xticks([]); plt.yticks([]);\n",
    "    if label: plt.xlabel(\"true: {}\".format(label), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import BallTree\n",
    "# predictor = KNN(X_all, y_all, 3, False)\n",
    "# distance, indices = predictor.balltree.query(X_all[6].reshape(1, -1) , 3)\n",
    "# print(indices)\n",
    "\n",
    "# view_digit(X_all[6])\n",
    "# view_digit(X_all[1304])\n",
    "# view_digit(X_all[2321])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UnweightedAccuracy = []\n",
    "# WeightedAccuracy = []\n",
    "# X = []\n",
    "\n",
    "# i = 1\n",
    "# for i in range(1, 5):\n",
    "#     X.append(i)\n",
    "    \n",
    "#     KNN_Unweighted = KNN(X_all, y_all, i , False) # Unweighted KNN\n",
    "#     yHatValid = KNN_Unweighted.predict(X_all)\n",
    "#     UnweightedConfusionMatrix = confusion_matrix(y_all, yHatValid)\n",
    "    \n",
    "#     Accuracy = (np.sum(np.diag(UnweightedConfusionMatrix)))/UnweightedConfusionMatrix.sum()\n",
    "# #     error = 1 - Accuracy\n",
    "    \n",
    "#     UnweightedAccuracy.append(Accuracy)\n",
    "#     print(\"Un: \", UnweightedAccuracy)\n",
    "    \n",
    "    \n",
    "#     KNN_Weighted = KNN(X_all, y_all, i , True) # Weighted\n",
    "#     yHatValid = KNN_Weighted.predict(X_all)\n",
    "#     WeightedConfusionMatrix = confusion_matrix(y_all, yHatValid)\n",
    "    \n",
    "#     Accuracy = (np.sum(np.diag(WeightedConfusionMatrix)))/WeightedConfusionMatrix.sum()\n",
    "# #     error = 1 - Accuracy    \n",
    "    \n",
    "#     WeightedAccuracy.append(Accuracy)\n",
    "#     print(\"W: \", WeightedAccuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Part A KNN\n",
    "###Scale the input data to zero mean and unit variance\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "scaler = preprocessing.StandardScaler().fit(X_all)\n",
    "x_all_scaled = pd.DataFrame(scaler.transform(X_all))\n",
    "pca = PCA(n_components=200)\n",
    "X_all_scaled_pca = pca.fit(x_all_scaled).transform(x_all_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelCV1 = KNeighborsClassifier(n_neighbors = 12,weights = 'distance') #best parameters found using gridsearch\n",
    "results11 = cross_validate(modelCV1, X_all, y_all, cv=10, scoring= 'accuracy', return_train_score=False)\n",
    "results12 = cross_validate(modelCV1, x_all_scaled, y_all, cv=10, scoring= 'accuracy', return_train_score=False)\n",
    "results13 = cross_validate(modelCV1, X_all_scaled_pca, y_all, cv=10, scoring= 'accuracy', return_train_score=False)\n",
    "print(\"Average Accuracy without scaling= \", results11['test_score'].mean(), ' std= ' ,results11['test_score'].std(), \"Max= \",results11['test_score'].max(), \"Min= \", results11['test_score'].min())\n",
    "print(\"Average Accuracy with scaling= \", results12['test_score'].mean(), ' std= ' ,results12['test_score'].std(), \"Max= \",results12['test_score'].max(), \"Min= \", results12['test_score'].min() )\n",
    "print(\"Average Accuracy after appying PCA= \", results13['test_score'].mean(), ' std= ' ,results13['test_score'].std(), \"Max= \",results13['test_score'].max(), \"Min= \", results13['test_score'].min() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Code to find best hyperparameters, sklearn provides GridSearchCV function to find best hyperparameters\n",
    "### GridsearchCV checks all combination of input hyperparameters and gives best possible combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters = {'n_neighbors': np.arange(6, 12, 2),'weights':('uniform', 'distance')}\n",
    "# scoring = {'Accuracy': 'accuracy', 'Log_loss': 'neg_log_loss'}\n",
    "# gs = GridSearchCV(KNeighborsClassifier(), return_train_score=True,param_grid=parameters, scoring=scoring, cv=10, refit='Accuracy')\n",
    "# gs.fit(X_all_scaled_pca,y_all)\n",
    "# results = gs.cv_results_\n",
    "# print(\"best params: \" + str(gs.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Construct a Linear Support Vector Machine classifier to make predictions on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "modelCV2 = svm.SVC(kernel='linear')\n",
    "results21 = cross_validate(modelCV2, X_all, y_all, cv=10, scoring= 'accuracy', return_train_score=False)\n",
    "results22 = cross_validate(modelCV2, x_all_scaled, y_all, cv=10, scoring= 'accuracy', return_train_score=False)\n",
    "print(\"Average Accuracy without scaling= \", results21['test_score'].mean(), ' std= ' ,results21['test_score'].std(), \"Max= \",results21['test_score'].max(), \"Min= \", results21['test_score'].min())\n",
    "print(\"Average Accuracy with scaling= \", results22['test_score'].mean(), ' std= ' ,results22['test_score'].std(), \"Max= \",results22['test_score'].max(), \"Min= \", results22['test_score'].min() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Code to find best hyperparameters, sklearn provides GridSearchCV function to find best hyperparameters\n",
    "# ### GridsearchCV checks all combination of input hyperparameters and gives best possible combination of hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "parameters = {'C': np.arange(1, 7, 1)}\n",
    "scoring = {'Accuracy': 'accuracy', 'Log_loss': 'neg_log_loss'}\n",
    "gs1 = GridSearchCV(svm.SVC(kernel='linear',probability=True), return_train_score=True,param_grid=parameters, scoring=scoring, cv=5, refit='Accuracy')\n",
    "gs1.fit(x_all_scaled,y_all)\n",
    "results = gs1.cv_results_\n",
    "print(\"best params: \" + str(gs1.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Construct a Feed-Forward Neural Network classifier to make predictions on the data. We recommend using Sklearn's [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) rather than the code you wrote in Homework 4. In our experiments we found training an MLPClassifier to take no more than a minute for reasonable choices of architectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "modelCV3 = MLPClassifier(hidden_layer_sizes = (784))\n",
    "results31 = cross_validate(modelCV3, X_all, y_all, cv=5, scoring= 'accuracy', return_train_score=False)\n",
    "results32 = cross_validate(modelCV3, x_all_scaled, y_all, cv=5, scoring= 'accuracy', return_train_score=False)\n",
    "# results33 = cross_validate(modelCV3, X_all_scaled_pca, y_all, cv=10, scoring= 'accuracy', return_train_score=False)\n",
    "print(\"Average Accuracy without scaling= \", results31['test_score'].mean(), ' std= ' ,results31['test_score'].std(), \"Max= \",results31['test_score'].max(), \"Min= \", results31['test_score'].min())\n",
    "print(\"Average Accuracy with scaling= \", results32['test_score'].mean(), ' std= ' ,results32['test_score'].std(), \"Max= \",results32['test_score'].max(), \"Min= \", results32['test_score'].min() )\n",
    "# print(\"Average Accuracy after appying PCA= \", results33['test_score'].mean(), ' std= ' ,results33['test_score'].std(), \"Max= \",results33['test_score'].max(), \"Min= \", results33['test_score'].min() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Running Grid search on Neural networks can be a very costly operation, it may take days.\n",
    "### So in this case as we have 784 features, I have used 1 hiddle layer with 784 units. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Which of the three models above performed the best on the data set?  Were you surprised or not surprised by your results?  Discuss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neural netwroks gave best accuracy as expected.\n",
    "# Whenever we get a new problem in ML, we should be able to decide which algorithm we should apply in that case. Following are the tricks which should be used to decide it,\n",
    "# 1) When to use Regression Algorithms: Number of features are small and number of training records are high.\n",
    "# 2) when to use SVM:  Number of features are high and number of training records are less.\n",
    "# 3) When to use Neural network: Number of features are high and number of training records are high as well.\n",
    "# In this case we can see that we have 784 features and 7.5k records, thats why neural network is giving better accuracy!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: For the best model you identified in **Part D**, perform a train-validation split and construct a confusion matrix based on predictions on the validation set.  Which classes tend to get confused with each other the most? Are there any classes for which your model performs exceptionally well?  Plot at least one misclassified example from each of the often-confused classes and suggests reasons why this behavior might occur.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.15, random_state=42)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes = (784))\n",
    "model.fit(x_train, y_train)\n",
    "print(model.score(x_train, y_train))\n",
    "predicted = model.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predicted,labels = [0, 1, 4, 7, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predicted,labels = [0, 1, 4, 7, 9] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### The confusion matrix shows that class 7 and 9 are most confused in each other\n",
    "### class 4 is performing exceptionally well\n",
    "###shape of class 7 and 9 are very similar, hence they are most confused\n",
    "index7 = np.where(y_all==7)\n",
    "index9 = np.where(y_all==9)\n",
    "print(index7)\n",
    "print(index9)\n",
    "view_digit(X_all[5])\n",
    "view_digit(X_all[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [30 points] Problem 2: Predicting Authors of Presidential Election Tweets \n",
    "***\n",
    "\n",
    "For the first time in history, the run-up to the 2016 presidential election saw candidates move a large portion of their campaigns from the traditional debating lectern to the Twitterverse. In this problem you will construct various classifiers to predict whether a tweet was sent by @HillaryClinton ($y=0$) or @realDonaldTrump ($y=1$). \n",
    "\n",
    "The data set contains $4000$ tweets that have been cleaned by converting all text to lowercase, removing punctuation, and removing hypertext links. In order to preserve hashtags we've replaced the typical # with the string `hashtag` (e.g. `#GiantMeteor` would be converted to `hashtaggiantmeteor`).  \n",
    "\n",
    "Execute the following cell to load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:16:43.620382Z",
     "start_time": "2018-04-19T11:16:43.607739Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = gzip.open('clean_tweets.pklz','rb')\n",
    "text_all, y_all = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Vectorize the text features using the Bag-of-Words text model **while removing stop words**.  Then answer the following questions: \n",
    "\n",
    "- How many distinct text features are there in the data after stop words are removed? \n",
    "- How many distinct **HashTags** are there in the data? \n",
    "- Which candidate uses HashTags the most frequently? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct text features in the data after stop words are removed =  7486\n",
      "Total Hashtags in the data =  1062\n",
      "Hashtags for Hillary Clinton =  804\n",
      "Hashtags for Donald Trump =  258\n",
      "Hillory clinton uses hashtags most frequently!\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "allstopwords = {}\n",
    "allfeatures = {}\n",
    "total_hashtags = 0\n",
    "hillory_hashtags = 0\n",
    "trump_hashtags = 0\n",
    "# Load stopwords\n",
    "f = open('stopwords.txt','r')\n",
    "\n",
    "for line in f:\n",
    "    word = line.strip()\n",
    "    if(word != \"\" and len(word) > 1):\n",
    "        allstopwords[word] = True\n",
    "# bag of words\n",
    "i = 0\n",
    "for row in text_all:\n",
    "    cc = str(row.lower()).count(\"hashtag\")\n",
    "    total_hashtags += cc\n",
    "    if(str(y_all[i]) == '1'):\n",
    "        hillory_hashtags += cc\n",
    "    else:\n",
    "        trump_hashtags += cc    \n",
    "    review_words = row.split()\n",
    "    for word in review_words:\n",
    "        if(word not in allstopwords):\n",
    "            if(word not in allfeatures):\n",
    "                allfeatures[word] = 1\n",
    "            else:\n",
    "                allfeatures[word] += 1\n",
    "    i = i+1\n",
    "print(\"Number of distinct text features in the data after stop words are removed = \", len(allfeatures))\n",
    "s = [(k, allfeatures[k]) for k in sorted(allfeatures, key=allfeatures.get, reverse=True)]\n",
    "top_features = {}\n",
    "inverse_top_features = {}\n",
    "count = 0\n",
    "n_top_features = 3500\n",
    "count = 0\n",
    "for e in s:\n",
    "    top_features[e[0]] = count\n",
    "    inverse_top_features[count] = e[0]\n",
    "    count += 1\n",
    "    if(count >= n_top_features):\n",
    "        break\n",
    "\n",
    "print(\"Total Hashtags in the data = \", total_hashtags)\n",
    "print(\"Hashtags for Hillary Clinton = \", hillory_hashtags)\n",
    "print(\"Hashtags for Donald Trump = \", trump_hashtags)\n",
    "if(hillory_hashtags > trump_hashtags):\n",
    "    print(\"Hillory clinton uses hashtags most frequently!\")\n",
    "elif(hillory_hashtags < trump_hashtags):\n",
    "    print(\"Donald Trump uses hashtags most frequently!\")\n",
    "else:\n",
    "    print(\"Both Donald Trump and Hillory clinton use hashtags equally!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare x_features\n",
    "x_features = np.zeros((len(text_all),n_top_features))\n",
    "for comment in range(0,len(text_all)):\n",
    "    words = text_all[comment].split()\n",
    "    wordcount={}\n",
    "    for w in words:\n",
    "        if(w in wordcount):\n",
    "            wordcount[w] += 1\n",
    "        else:\n",
    "            wordcount[w] = 1\n",
    "    for w in wordcount:\n",
    "        if(w in top_features):\n",
    "            x_features[comment][top_features[w]] = wordcount[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### There are 7451 distict words in the dataset. \n",
    "### But using all 7451 as features in not a good idea as there are some words which occur only once in the whole dataset and \n",
    "##  such words dont have potential to classify the comments. \n",
    "### trying following values [2000,2500,3000,3500,4000,4500] as number of features, I found that best accuracy is achieved at 3500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Construct a Logistic Regression classifier with L2 regularization to make predictions on the data. Exactly as in **Problem 1**, you should clearly detail your process for picking optimal hyperparameters and evaluating your model, and report the details of your best model along with final validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy using Logistic Regression= 0.9225000000000001 ,std= 0.016007810593582125 ,Max= 0.9475 ,Min= 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "modelCV4 = LogisticRegression(C=1.2000100000000002, class_weight=None, dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "results211 = cross_validate(modelCV4, x_features, y_all, cv=10, scoring= 'accuracy', return_train_score=False)\n",
    "print(\"Average Accuracy using Logistic Regression=\", results211['test_score'].mean(), ',std=' ,results211['test_score'].std(), \",Max=\",results211['test_score'].max(), \",Min=\", results211['test_score'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This section of the code is using gridsearch to best best hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': np.arange(1e-05, 3, 0.1)}\n",
    "scoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\n",
    "gs = GridSearchCV(LogisticRegression(), return_train_score=True,\n",
    "                  param_grid=param_grid, scoring=scoring, cv=10, refit='Accuracy')\n",
    "gs.fit(x_features, y_all)\n",
    "results = gs.cv_results_\n",
    "print(\"best params: \" + str(gs.best_estimator_))\n",
    "# best params found using gridsearch: LogisticRegression(C=1.2000100000000002, class_weight=None, dual=False,\n",
    "#           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "#           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "#           solver='liblinear', tol=0.0001, verbose=0, warm_start=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Determine and report the 10 words that are the best predictors for @HillaryClinton and the 10 words that are the best predictors for @realDonaldTrump in your Logistic Regression model. In addition, you should briefly discuss how you found these best features mathematically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Construct a Naive Bayes classifier to make predictions on the data. Again, you should clearly detail your process for picking optimal hyperparameters and evaluating your model, and report the details of your best model along with final validation accuracy. **Hint**: Since text features are discrete, you'll want to use Sklearn's [MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "modelCV5 = MultinomialNB(alpha = 0.85, fit_prior = True)\n",
    "results221 = cross_validate(modelCV5, x_features, y_all, cv=10, scoring= 'accuracy', return_train_score=False)\n",
    "print(\"Average Accuracy without scaling= \", results221['test_score'].mean(), ' std= ' ,results221['test_score'].std(), \"Max= \",results221['test_score'].max(), \"Min= \", results221['test_score'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This section of the code is using gridsearch to best  hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': np.arange(0.1, 1.2, 0.2), 'fit_prior':('True','False')}\n",
    "scoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\n",
    "gs = GridSearchCV(MultinomialNB(), return_train_score=True,\n",
    "                  param_grid=param_grid, scoring=scoring, cv=10, refit='Accuracy')\n",
    "gs.fit(x_features, y_all)\n",
    "results = gs.cv_results_\n",
    "print(\"best params: \" + str(gs.best_estimator_))\n",
    "# best params found: MultinomialNB(alpha=0.30000000000000004, class_prior=None, fit_prior='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Determine and report the 10 words that are the best predictors for @HillaryClinton and the 10 words that are the best predictors for @realDonaldTrump in your Naive Bayes model. In addition, you should briefly discuss how you found these best features mathematically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 predictive features in case of Naive bayes are:\n",
      "hillary_esp\n",
      "weve\n",
      "billclinton\n",
      "flotus\n",
      "joebiden\n",
      "thebriefing2016\n",
      "deserve\n",
      "timkaine\n",
      "hfa\n",
      "kids\n",
      "10 words that are the best predictors for @DonaldTrump: will of is you in and to https co the\n",
      "10 words that are the best predictors for @HillaryClintonHC: ⁰⁰i rescue foot footage requires repudiate republicano republicana republic forcefully\n"
     ]
    }
   ],
   "source": [
    "## The Recursive Feature Elimination (RFE) method is most common feature selection approach. \n",
    "### I have used RFE to select top 10 features which have highest potential to classify a comment\n",
    "### 10 words that are the best predictors for @HillaryClinton\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "x_features_top200 = x_features[:,0:200]\n",
    "from sklearn.feature_selection import RFE\n",
    "model = MultinomialNB()\n",
    "# create the RFE model and select 10 attributes\n",
    "rfe = RFE(model, 10)\n",
    "rfe = rfe.fit(x_features_top200, y_all)\n",
    "ranks = rfe.ranking_\n",
    "most_predictive={}\n",
    "for index in range(0,200):\n",
    "    if(ranks[index] <= 10):\n",
    "        most_predictive[index] = ranks[index]\n",
    "s = [(k, most_predictive[k]) for k in sorted(most_predictive, key=most_predictive.get, reverse=False)]\n",
    "print(\"Top 10 predictive features in case of Naive bayes are:\")\n",
    "for i in range(1,11):\n",
    "    print(inverse_top_features[s[i][0]])\n",
    "class TweetFeaturizer2:\n",
    "    def __init__(self):\n",
    "        \n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        self.vectorizer = CountVectorizer()\n",
    "        \n",
    "    def add_text_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method for looping over original text and adding new text \n",
    "        features. \n",
    "        :param examples: the list of raw tweets \n",
    "        \"\"\"\n",
    "        \n",
    "        new_examples = [] \n",
    "        for ex in examples:\n",
    "            # here is where you might try to add new features \n",
    "            # currently this does nothing.  \n",
    "            new_examples.append(ex)\n",
    "            \n",
    "        return new_examples\n",
    "\n",
    "    def build_train_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in training text features and do further feature engineering \n",
    "        Most of the work in this homework will go here, or in similar functions  \n",
    "        :param examples: the list of raw tweets \n",
    "        \"\"\"\n",
    "        \n",
    "        new_examples = self.add_text_features(examples)\n",
    "        return self.vectorizer.fit_transform(new_examples)\n",
    "\n",
    "    def get_test_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in test text features and transform the same way as train features \n",
    "        :param examples: the list of raw tweets\n",
    "        \"\"\"\n",
    "        new_examples = self.add_text_features(examples)\n",
    "        return self.vectorizer.transform(new_examples)\n",
    "\n",
    "    def show_top10(self):\n",
    "        \"\"\"\n",
    "        prints the top 10 features for the positive class and the \n",
    "        top 10 features for the negative class. \n",
    "        \"\"\"\n",
    "        feature_names = np.asarray(self.vectorizer.get_feature_names())\n",
    "        top10 = np.argsort(self.NB.coef_[0])[-10:]\n",
    "        bottom10 = np.argsort(self.NB.coef_[0])[:10]\n",
    "        print(\"10 words that are the best predictors for @DonaldTrump: %s\" % \" \".join(feature_names[top10]))\n",
    "        print(\"10 words that are the best predictors for @HillaryClintonHC: %s\" % \" \".join(feature_names[bottom10]))\n",
    "                \n",
    "    def train_model(self, random_state=1234):\n",
    "        \"\"\"\n",
    "        Method to read in training data from file, and \n",
    "        train Logistic Regression classifier. \n",
    "        \n",
    "        :param random_state: seed for random number generator \n",
    "        \"\"\"\n",
    "        \n",
    "        from sklearn.linear_model import LogisticRegression \n",
    "        \n",
    "        # load data \n",
    "        f = gzip.open('raw_tweets_train.pklz','rb')\n",
    "        text_all, y_all = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        # get training features and labels \n",
    "        self.X_train = self.build_train_features(text_all)\n",
    "        self.y_train = y_all\n",
    "        \n",
    "        # train logistic regression model.  !!MUST USE LogisticRegression!! \n",
    "        self.NB = MultinomialNB()\n",
    "        self.NB.fit(self.X_train, self.y_train)\n",
    "        \n",
    "\n",
    "# Instantiate the class \n",
    "feat = TweetFeaturizer2()\n",
    "\n",
    "# Train your NB \n",
    "feat.train_model(random_state=1234)\n",
    "\n",
    "# Show the top 10 features for each class \n",
    "feat.show_top10()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Which of the two models above performed the best on the data set?  Were you surprised or not surprised by your results?  Discuss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Performed better than Logistic regression. I am not surprised with this, it was expected. Naive Bayes is most \n",
    "# commonly used for text classification tasks like Spam detection, Topic mining, Categorization etc. Given problem is  \n",
    "# version of text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [25 points] Problem 3: Feature Engineering and Presidential Tweets \n",
    "***\n",
    "\n",
    "In this problem you will again work with the Twitter election data from **Problem 2**, but this time in its unadulterated raw form. Unlike in **Problem 2**, you will only be allowed to use Logistic Regression as your classifier.  Instead of using a fancier model, you will attempt to improve performance by crafting better features.  One way you might do this is to explore text models that are more sophisticated that simple Bag-of-Words. Alternatively, you might explore the training data and identify characteristics of tweets by a particular author that you can then turn into a feature. \n",
    "\n",
    "The class `TweetFeaturizer` shown below is already fully functional.  Your goal in this problem is to make it better.  In it's current state, the class reads in the training and test data, fits a Logistic Regression model using Bag-of-Words, makes predictions on the test set, and then dumps the predictions to a csv file that can be uploaded to Kaggle. You are free to modify this class is any way that you see fit, but we've given you some helpful functionality that will prove sufficient for most of you.  The `add_text_features` method currently loops over each tweet in the data set, copies it to a new array, and then passes that array into the text vectorizer.  One way to create new features is to append distinct word-indicators onto the string representing the tweet.  These will then be turned into features by the vectorizer. \n",
    "\n",
    "As an example (that is intentionally silly and probably unhelpful): Suppose you think a potentially helpful feature is whether or not the tweet contains more than 10 instances of the letter `z`.  In `add_text_features` you could count the number of `z`'s in a tweet and if there are more than 10, you could append the word `MoreThanTenZs` to the tweet.  Then, when the tweet is passed into the vectorizer, this will turn into a numerical feature.  \n",
    "\n",
    "In addition to competing against yourself to craft the best features that you can, you'll also compete against your classmates in a Kaggle competition.  The competition page can be found here: \n",
    "\n",
    "https://www.kaggle.com/c/4622-election-tweet-authorship\n",
    "\n",
    "A private invite link will be available on Piazza which will get you into the competition. Note that the test data has been partitioned into a public leaderboard set and a private leaderboard set.  While the competition is open, submitting to Kaggle will tell you your score on the public leaderboard.  Your scores on the private leaderboard will become available at the end of the competition.   The top **THREE** students on the **Private** leaderboard at the end of the competition will earn 10 extra credit points on the Practicum. Note that to prevent the machine learning-equivalent of button mashing, we've limited you to **10** submissions per day.  You should be evaluating your features locally with cross-validation and then submitting to Kaggle when you think you have something that works.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: **Feature Engineering**:  What you need to do: \n",
    "\n",
    "- Explore and experiment with the data to try to find good features \n",
    "- Implement these features in the `TweetFeaturizer` class  \n",
    "- Implement some evaluation methods to see how well your features improve your model (*cough* cross-validation *cough*) \n",
    "- Make submissions to the Kaggle competition and see how you compared to your classmates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this part we need to add certain new words into tweet, which will help our logistic regression model to imporve performance!\n",
    "# So the the question now is how should we add the words into a tweet? which words should be added?\n",
    "# So, to improve accuracy of our model, our plan is to make a guess category of a tweet using a logic and add some unique words into it so that \n",
    "# logistic regression will be able to identify it.\n",
    "\n",
    "# So,  How to guess category of a tweet?\n",
    "# We are given a function show_top10. This function shows top words which are strong indicator of Hillory clinton class \n",
    "# and top words which are strong indicators of Donald trump class. So, According to presence of top words we will add new words into sentence!\n",
    "\n",
    "# And what words should be added to a tweet?\n",
    "# I will keep a list of top 100 words of each both classes using show_top10().\n",
    "# Then in each commnet I will count number of times a word in top 100 occurs in the tweet.\n",
    "# Ex1. lets say 10 indicators of Trump occur in a tweet and 4 indicators of Cliton occur in same tweet.\n",
    "# So we will insert a word \"dtindicator\" (10 - 4) = 6 times at the back of the tweet.\n",
    "# Ex2. lets say 7 indicators of Trump occur in a tweet and 11 indicators of Cliton occur in same tweet.\n",
    "# So we will insert a word \"hcindicator\" (11 - 7) = 4 times at the back of the tweet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: **Motivation and Analysis**: What you need to do: \n",
    "\n",
    "Convince me that:\n",
    "\n",
    "- Your new features work\n",
    "- You understand what the new features are doing\n",
    "- You had a clear methodology for incorporating the new features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apart from above precessing, I have cleaned the data by following methode\n",
    "# 1) convert into lowercase\n",
    "# 2) remove urls\n",
    "# 3) Lemmatization\n",
    "# 4) remove punctuation and digits\n",
    "# 5) remove stopwords\n",
    "# I have divided the input data into 95% for training and 5% for testing, I got 92.5% accuracy on test data!\n",
    "# New features are giving a clue to classifier about the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:17:43.721148Z",
     "start_time": "2018-04-19T11:17:43.346867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import operator\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "allstopwords = {}\n",
    "f = open('stopwords.txt','r')\n",
    "for line in f:\n",
    "    word = line.strip()\n",
    "    if(word != \"\" and len(word) > 2):\n",
    "        allstopwords[word] = True\n",
    "class TweetFeaturizer:\n",
    "    def __init__(self):\n",
    "        \n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        self.vectorizer = CountVectorizer()\n",
    "    def remove_stopwords(self,tweet):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = tweet.split()\n",
    "        outwords = []\n",
    "        for w in words:\n",
    "            ww = lemmatizer.lemmatize(w)\n",
    "            if(not(ww in allstopwords) and len(ww) > 1):\n",
    "                outwords.append(ww)\n",
    "        return \" \".join(outwords)\n",
    "    def clean_tweet(self,ex):\n",
    "          ex = ex.lower()\n",
    "          ex = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', ex, flags=re.MULTILINE)\n",
    "          tmp_ex = ex.replace(\"!\",\" \").replace(\"@\",\" \").replace(\"#\",\" \").replace(\"$\",\" \")\n",
    "          tmp_ex = tmp_ex.replace(\"%\",\" \").replace(\"^\",\" \").replace(\"&\",\" \").replace(\"*\",\" \")\n",
    "          tmp_ex = tmp_ex.replace(\"(\",\" \").replace(\")\",\" \").replace(\",\",\" \").replace(\".\",\" \")\n",
    "          tmp_ex = tmp_ex.replace(\"/\",\" \").replace(\"\\\\\",\" \").replace(\"?\",\" \").replace(\"0\",\" \")\n",
    "          tmp_ex = tmp_ex.replace(\"1\",\" \").replace(\"2\",\" \").replace(\"3\",\" \").replace(\"4\",\" \")\n",
    "          tmp_ex = tmp_ex.replace(\"5\",\" \").replace(\"6\",\" \").replace(\"7\",\" \").replace(\"8\",\" \")\n",
    "          tmp_ex = tmp_ex.replace(\"9\",\" \").replace(\"_\",\" \").replace(\"-\",\" \").replace(\"+\",\" \")\n",
    "          tmp_ex = tmp_ex.replace(\":\",\" \").replace(\";\",\" \").replace(\"<\",\" \").replace(\">\",\" \")\n",
    "          tmp_ex = re.sub(' +', ' ', tmp_ex)\n",
    "          return tmp_ex\n",
    "    def add_text_features(self, examples):\n",
    "        DT_indicators = {}\n",
    "        HC_indicators = {}\n",
    "        DT_top50 = \"zteiwnqz beat tomorrow watching directly vote obama amazing deal weak failing touch system benghazi radical isi makeamericasafeagain bernie sander wonderful press donaldtrump dem newtgingrich hv join vega statement danscavino gopconvention looking primary anncoulter enjoy trade continue smart condolence bring mail melania interviewed totally trumptrain ltg erictrump morning interesting ted trumpocrats prayer tired supporter nice story bad drudge goofy win corrupt dtindicator imwithyou terrorism victim follower pm cruz rally foxnews safe teamtrump votetrump gop lyin washington record wisconsin ivankatrump via speech amp great delegate trumppence crookedhillary donaldjtrumpjr report york maga realdonaldtrump poll thank email cnn border clinton americafirst medium makeamericagreatagain crooked\"\n",
    "        HC_top50 = \"http barack timkaine potus joebiden there let demsinphilly rt flotus ve hillary berniesanders idea billclinton donald voice dream good the this and willing re history friend business here mother chelseaclinton union proud ztggmmfhqg tax foreign help you thebriefing deserve prepared serve debatenight build demconvention lnrjcakpjw carrier pigeon ll company america college chief start ago what life running refusing week we pay lgbt gold who stronger inspired nationalvoterregistrationday disability child su mom real rncinclehttps can latino none greater gabbygiffords diplomacy election relationship make teamusa womensequalityday hfa parent muslim matter nc heart tweet white income paying enough enquirer corybooker they that elizabethforma\"\n",
    "        for w in DT_top50.split():\n",
    "            DT_indicators[w] = True\n",
    "        for w in HC_top50.split():\n",
    "            HC_indicators[w] = True        \n",
    "        new_examples = []\n",
    "        for ex in examples:\n",
    "            tmp_ex = self.clean_tweet(ex)\n",
    "            count_DT_indicators = 0\n",
    "            count_HC_indicators = 0\n",
    "            for w in tmp_ex.split():\n",
    "                if(w in DT_indicators):\n",
    "                    count_DT_indicators += 1\n",
    "                if(w in HC_indicators):\n",
    "                    count_HC_indicators += 1\n",
    "            if(count_DT_indicators > count_HC_indicators):\n",
    "                tmp = \"dtindicator\"\n",
    "                for i in range(0,(count_DT_indicators - count_HC_indicators) + 1):\n",
    "                    tmp_ex = tmp_ex + \" \" + tmp\n",
    "            elif(count_DT_indicators < count_HC_indicators):\n",
    "                tmp = \"hcindicator\"\n",
    "                for i in range(0,abs(count_DT_indicators - count_HC_indicators) + 1):\n",
    "                    tmp_ex = tmp_ex + \" \" + tmp\n",
    "            tmp_ex = self.remove_stopwords(tmp_ex)\n",
    "            new_examples.append(tmp_ex)            \n",
    "        return new_examples\n",
    "\n",
    "    def build_train_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in training text features and do further feature engineering \n",
    "        Most of the work in this homework will go here, or in similar functions  \n",
    "        :param examples: the list of raw tweets \n",
    "        \"\"\"\n",
    "        \n",
    "        new_examples = self.add_text_features(examples)\n",
    "        return self.vectorizer.fit_transform(new_examples)\n",
    "\n",
    "    def get_test_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in test text features and transform the same way as train features \n",
    "        :param examples: the list of raw tweets\n",
    "        \"\"\"\n",
    "        new_examples = self.add_text_features(examples)\n",
    "        return self.vectorizer.transform(new_examples)\n",
    "\n",
    "    def show_top10(self):\n",
    "        \"\"\"\n",
    "        prints the top 10 features for the positive class and the \n",
    "        top 10 features for the negative class. \n",
    "        \"\"\"\n",
    "        feature_names = np.asarray(self.vectorizer.get_feature_names())\n",
    "        top10 = np.argsort(self.logreg.coef_[0])[-10:]\n",
    "        bottom10 = np.argsort(self.logreg.coef_[0])[:10]\n",
    "        print(\"DT: %s\" % \" \".join(feature_names[top10]))\n",
    "        print(\"HC: %s\" % \" \".join(feature_names[bottom10]))\n",
    "                \n",
    "    def train_model(self, random_state=1234):\n",
    "        \"\"\"\n",
    "        Method to read in training data from file, and \n",
    "        train Logistic Regression classifier. \n",
    "        \n",
    "        :param random_state: seed for random number generator \n",
    "        \"\"\"\n",
    "        \n",
    "        from sklearn.linear_model import LogisticRegression \n",
    "        \n",
    "        # load data \n",
    "        f = gzip.open('raw_tweets_train.pklz','rb')\n",
    "        text_train, y_train = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        # get training features and labels \n",
    "        self.x = self.build_train_features(text_train)\n",
    "        self.y = y_train\n",
    "        nx_train, nx_test, ny_train, ny_test = train_test_split(self.x, self.y, test_size=0.05, random_state=42)        \n",
    "        # train logistic regression model.  !!MUST USE LogisticRegression!! \n",
    "        self.nx_train = nx_train;\n",
    "        self.ny_train = ny_train;\n",
    "        self.nx_test = nx_test;\n",
    "        self.ny_test = ny_test;        \n",
    "        self.logreg = LogisticRegression(random_state=random_state)\n",
    "        self.logreg.fit(self.nx_train, self.ny_train)\n",
    "    def model_predict(self):\n",
    "        \"\"\"\n",
    "        Method to read in test data from file, make predictions\n",
    "        using trained model, and dump results to file \n",
    "        \"\"\"\n",
    "        \n",
    "        # read in test data \n",
    "        f = gzip.open('raw_tweets_test.pklz','rb')\n",
    "        text_valid = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        # featurize test data \n",
    "        self.X_test = self.get_test_features(text_valid)\n",
    "        \n",
    "        # make predictions on test data \n",
    "        pred = self.logreg.predict(self.X_test)\n",
    "        \n",
    "        # dump predictions to file for submission to Kaggle  \n",
    "        pd.DataFrame({\"realDonaldTrump\": np.array(pred, dtype=bool)}).to_csv(\"prediction.csv\", index=True, index_label=\"Id\")\n",
    "        \n",
    "\n",
    "# Instantiate the class \n",
    "feat = TweetFeaturizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train your Logistic Regression classifier \n",
    "feat.train_model(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT: border realdonaldtrump clinton email cnn americafirst makeamericagreatagain medium thank crooked\n",
      "HC: barack timkaine potus let joebiden rt http demsinphilly there ve\n",
      "0.925\n"
     ]
    }
   ],
   "source": [
    "# Show the top 10 features for each class \n",
    "feat.show_top10()\n",
    "print(feat.logreg.score(feat.nx_test, feat.ny_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make prediction on test data and produce Kaggle submission file \n",
    "feat.model_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
